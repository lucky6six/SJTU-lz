% !TEX root = ../main.tex

\chapter{细粒度冗余识别的重复数据删除系统设计}


\section{现有问题分析与设计目标}

随着 AI 模型数据在云存储中的比重日益增加，以及数据块大小的持续增长，传统重复数据删除系统在处理现代云存储工作负载时，其局限性愈发凸显。具体而言，传统系统主要面临以下挑战：

\begin{enumerate}
    \item \textbf{对模型数据的去重效果不佳}：传统去重系统依赖字节级别的精确匹配来识别冗余。然而，
    AI 模型文件普遍存在数值冗余，即不同数据块在数值上高度相似但字节表示上存在细微差异。
    这种特性使得传统系统难以通过简单的指纹比对有效识别此类冗余，导致去重率大幅下降。如图~\ref{fig:b}所示，
    在一个包含文件数据（非模型）与 Transformer 模型 checkpoints（模型）的混合负载下，开源块级去重系统 Destor 
    结合 Zstd 压缩算法的去重率\footnote{去重率 = 存储数据原始大小 / 去重压缩后大小}随着模型数据占比的增加而显著降低。当模型数据占比达到 100\% 时，去重率几乎降至 1，直观地暴露了其在处理模型数值冗余方面的短板。

    \begin{figure}[htbp]
        \centering
        \includegraphics[width=0.8\textwidth]{../figures/系统去重率随模型数据比例变化情况.pdf}
        \bicaption{系统去重率随模型数据比例变化情况}{Deduplication rate variation with model data proportion}\label{fig:b}
    \end{figure}

    \item \textbf{对大块数据的去重能力有限}：随着存储块平均大小的增加，数据块内部往往包含大量局部重复内容。传统系统在分块时无法有效捕捉这些局部重复，导致大量冗余未被识别和消除。如图~\ref{fig:c}所示，在使用多个版本的 Linux 系统源码 tar 包作为负载时，Destor 系统的去重率随数据块平均大小的增加而明显下降，反映了其处理大块数据局部重复的不足。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/系统去重率随数据块平均大小变化情况.pdf}
    \bicaption{系统去重率随数据块平均大小变化情况}{deduplication rate variation with average data block size}
    \label{fig:c}
\end{figure}

    \item \textbf{存储与计算开销较高}：为了提升去重效果，传统系统不得不采用更复杂的切块和指纹计算方法，这无疑增加了系统的存储和计算开销，进而影响了整体性能和可扩展性。这也是增量压缩等更细粒度的去重技术难以在工业界大规模应用的主要原因。
\end{enumerate}

尽管传统方法效果不佳，但这些新型数据中蕴含着大量未被有效利用的\textbf{细粒度冗余}，具体包括：
\begin{itemize}
    \item \textbf{模型数值冗余}：主要表现为浮点数（如 BF16/FP32）的指数高位高度相似，而尾数位存在细微差异。如图~\ref{fig:d}所示，通过分析 Transformer 模型文件中 BF16 浮点数各比特位的熵值\footnote{熵值用于衡量该位的不确定性或不相似程度，数据越集中则熵值越低。熵为 0 表示该位在所有采样数据中取值完全相同（全 0 或全 1）~\cite{shannon2001mathematical}。}可以发现，9\textasciitilde14 位的指数部分熵值远低于尾数部分，表明这些位存在大量冗余，而传统方法无法利用这一点。
    \item \textbf{大块数据的局部重复}：在非模型数据的大块中，即使整个数据块不完全相同，其内部也常常包含大量相同或高度相似的局部内容。
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/模型文件中BF16浮点数各bit位熵值.pdf}
    \bicaption{模型文件中 BF16 浮点数各 bit 位熵值}{Bit entropy values of BF16 floating-point numbers in model files}\label{fig:d}
\end{figure}

针对上述问题，现有的优化方案各有局限。Finesse、Odess 等系统引入了增量压缩，能更深入地挖掘数据冗余，但计算开销高昂，且对模型数据无效。另一方面，专用的模型压缩方法（如 ZipNN、ZipLLM）虽然高效，但高度依赖模型数据的特定结构，无法应用于混合工作负载的云存储系统，甚至可能对非模型数据产生负优化。

基于以上分析，我们发现当前去重系统的核心挑战在于缺乏一种统一的机制来识别和处理以模型数值冗余和大块数据局部重复为代表的细粒度冗余。现有方法往往顾此失彼，无法兼顾效率、效果与通用性。为此，我们提出以下设计目标：
\begin{enumerate}
    \item \textbf{数据类型鉴别}：系统应具备区分模型数据与非模型数据的能力，以便针对性地处理模型数值冗余和大块数据的局部重复。
    \item \textbf{差异化去重策略}：系统需能根据识别出的数据类型，采用相应的去重策略，以最大化去重效果。
    \item \textbf{计算与存储开销控制}：在保证去重效果的同时，必须严格控制额外的计算与存储开销，避免对系统整体性能造成显著影响。
    \item \textbf{低侵入性集成}：系统设计应与现有云存储的传统去重工作流兼容，尽可能降低集成复杂度和对现有系统的改造。
\end{enumerate}


\section{系统总体架构设计}
基于此，我们提出了一种面向混合负载\footnote{混合负载指存储目标中既有模型数据，又有传统的文本、日志、代码等数据}的细
粒度冗余识别重复数据删除系统（Fine-grained Hybrid Redundancy Deduplication, FHRD），其总体架构如
图~\ref{fig:FHRD_architecture}所示。该系统在传统块级去重和通用压缩工作流的基础上，集成了多个新模块，
赋予了系统数据类型鉴别、模型数据数值冗余提取以及大块数据局部重复识别的能力。其核心在于突破了传统单一去重策略
的限制，引入了基于内容的数据类型鉴别机制，并在此基础上实现了自适应的差异化处理流程，针对模型文件的数值冗余
和大块数据的局部重复分别进行了专门的去重策略设计与优化。

系统的工作流程始于存储接口层。该层负责读取配置文件、调整系统参数，并接收来自上层应用的输入，
将待存储文件转化为数据流暂存于数据缓冲区。数据首先经由传统的块级重复数据删除模块处理，该模块包含段管理器、
文件结构缓存、哈希引擎及重复块查找器等核心组件，负责完成数据分块、指纹计算与初步的全局重复数据查找，
其设计与主流工业实践保持一致，确保了系统的基础去重效能与兼容性。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{../figures/细粒度冗余识别的重复数据删除系统总体架构.drawio.pdf}
    \bicaption{细粒度冗余识别的重复数据删除系统总体架构}{overall architecture of fine-grained redundancy-aware deduplication system}
    \label{fig:FHRD_architecture}
\end{figure}

系统的核心创新在于\textbf{数据鉴别层}和\textbf{细粒度处理层}（即图中红色部分）。经过传统去重后的唯一数据块，并不会直接进入压缩阶段，而是被送入数据类型鉴别模块。该模块通过数据抽样、字节分组、熵值分析等手段，对数据块的底层内容特征进行实时、轻量级的分析，精确判别其为“模型数据块”或“非模型数据块”。

对于被识别出的\textbf{模型数据块}，系统将其路由至模型数据处理模块。该模块深度挖掘浮点数张量中存在的数值相似性冗余（即指数位高位重复）。通过数据类型鉴别模块的分组熵值分析结论，识别出指数位所在区域，然后通过重组算法进行编码，将冗余区域集中，从而将不可压缩的数据块变为可部分压缩的数据块，有效消除传统方法无法触及的冗余。

对于被识别出的\textbf{非模型数据块}，系统则将其导向非模型数据处理模块。该模块集成了细粒度特征提取引擎与相似块查找器，能够发现相似数据块，而后调用冗余去除器，以子块粒度去除传统大块数据的连续重复冗余，并对剩余的差异量（diff）进行压缩，实现对传统大块更深层次的去重。

最终，所有处理完毕的数据块（包括经专用编码的模型数据块和经增量压缩后的差异数据）进入\textbf{持久化存储层}。系统通过容器管理策略，将数据及其元数据（包括指纹索引和细粒度特征索引）高效地存入物理存储设备中，完成整个数据处理闭环。

该架构通过流水线集成设计和智能的数据路由，成功地将传统去重、数据类型鉴别、多种细粒度冗余消除技术以及通用压缩算法融合为一个协同工作的整体，显著提升了系统在混合负载场景下的综合数据缩减效率。

\section{混合数据类型鉴别}
\subsection{类型鉴别目标}
数据类型鉴别模块旨在精确区分“模型数据块”与“非模型数据块”，其最终目的是在统一的框架内，为不同类型的数据匹配最合适的处理路径：对模型数据进行专门的数值冗余消除处理，同时避免对非模型数据施加不必要的计算，从而防止负优化。

因此，本文所定义的\textbf{模型数据}，并非指具有特定文件后缀（如 \texttt{.safetensors}、\texttt{.pt}）的文件，而是指那些在内容上包含大量 32 位或 16 位浮点数张量的数据块。这些数据块通常在模型训练过程中生成，其数据内容如图~\ref{fig:float_binary}所示，蕴含着显著的指数位冗余（如图中红框内部分所示），因此适合进行专门的数值冗余消除。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{../figures/浮点数二进制.png}
    \bicaption{16 位浮点数二进制内容}{Binary representation of 16-bit floating-point numbers}\label{fig:float_binary}
\end{figure}

\subsection{块级鉴别}
基于上述定义，若仅依赖文件格式进行判断，将导致大量误判。例如，一个数据包（如 \texttt{.tar}）或磁盘镜像（如 \texttt{.img}）可能同时包含模型与非模型数据；反之，一个模型权重文件内部也可能包含文件头、元数据等不具备数值冗余特性的“非模型”部分。因此，必须深入数据内容特征进行分析。

如表~\ref{tab:comparison_of_identification_granularity}所示，与文件级鉴别相比，在块级粒度进行数据类型鉴别具有显著优势：
\begin{enumerate}
    \item \textbf{精确识别}：块级鉴别能够针对数据块的实际内容进行分析，精准区分混合在同一文件中的模型数据与非模型数据，避免了文件级鉴别带来的误判风险。
    \item \textbf{灵活适应}：能够灵活适应包含多种数据类型的混合负载场景，确保每个数据块都得到最恰当的处理。
    \item \textbf{避免负优化}：通过精确识别，系统可以避免对非模型数据（如高熵的量化模型、文件头等）执行无效的数值冗余处理，从而规避性能开销和潜在的体积膨胀。
    \item \textbf{易于集成}：块级鉴别可以作为独立模块无缝嵌入到传统块级去重流水线中，对现有系统侵入性低，易于部署。
\end{enumerate}

\begin{table}[!hpt]
    \bicaption{鉴别粒度对比表}{Comparison of identification granularity}\label{tab:comparison_of_identification_granularity}
    \centering
    \begin{tabular}{@{} >{\raggedright\arraybackslash}p{0.3\linewidth}
                                            >{\raggedright\arraybackslash}p{0.3\linewidth}
                                            >{\raggedright\arraybackslash}p{0.3\linewidth} @{}}
        \toprule
        \textbf{鉴别粒度} & \textbf{块级} & \textbf{文件级} \\ \midrule
        tar、iso 等打包文件 &
            能识别其中的模型数据部分 &
            全部误判为非模型文件 \\\midrule
        用户自定义后缀的模型文件 &
            能够识别模型数据 &
            无效 \\\midrule
        \texttt{Q4} 等高熵量化模型 &
            可识别为非模型数据，避免处理 &
            误判为模型数据，产生负优化 \\\midrule
        \texttt{header} 等模型文件中的非模型部分 &
            可识别为非模型数据，避免处理 &
            误判为模型数据，产生负优化 \\\midrule
        集成侵入性 &
            低，可作为独立模块嵌入块处理流水线 &
            高，需改造文件处理逻辑 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{基于分组熵值分析的数据类型鉴别方法}
如图~\ref{fig:float_binary}所示，模型数据块中的浮点数，其指数位通常集中在特定的比特位范围内（例如，16 位浮点数的第 9\textasciitilde14 位），这些位的熵值显著低于其他部分。而非模型数据块则缺乏这种清晰的熵值分布特征。利用这一差异，我们设计了基于分组熵值分析的数据类型鉴别方法，如图~\ref{fig:data_type_classification}所示。

该方法首先对数据块进行随机抽样以降低计算开销，然后将采样字节按位分组，并计算每个比特位分组的熵值。通过分析熵值分布曲线：
\begin{itemize}
    \item 若第 9\textasciitilde14 位熵值显著低于其他位，则判定为 16 位浮点数模型数据块。
    \item 若第 25\textasciitilde30 位熵值显著低于其他位，则判定为 32 位浮点数模型数据块\footnote{分别对应 BF16 和 FP32 格式浮点数的指数高位。}。
    \item 若无明显低熵区间，则判定为非模型数据块。
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{../figures/数据类型鉴别模块.drawio.pdf}
    \bicaption{基于分组熵值分析的数据类型鉴别方法}{Data type classification method based on grouped entropy analysis}\label{fig:data_type_classification}
\end{figure}


\section{差异化数据处理}

\subsection{模型编码压缩方法}
模型数据中存在的数值冗余无法被传统通用压缩算法有效识别，其根本原因在于此类冗余的独特分布模式与通用压缩算法（如 LZ 系列）的核心工作原理不匹配。通用压缩算法擅长处理字节流中的\textbf{局部连续性冗余}，它们通过滑动窗口识别并压缩在窗口内重复出现的连续字节序列。

然而，模型数据中的冗余模式（即重复的指数位高位）在字节流层面是\textbf{非连续的}。这些承载关键冗余信息的比特分散在每个浮点数的特定位域中，例如，在 32 位浮点数序列中，具有相似模式的指数位可能间隔数个字节才出现一次。这种跨字节的非连续分布，使得通用压缩算法难以捕捉到结构性冗余，反而会因尝试对高度随机的尾数位进行无效匹配而引入不必要的计算开销，导致“负优化”。

为解决此问题，如图~\ref{fig:model_data_processing}所示，本文采用专用编码算法对模型数据块进行处理。该算法首先对数据块中的每个浮点数进行细粒度的按位拆分，将所有符号位、指数位、尾数位分别集中在一起，形成不同的“位平面”（Bit Plane）。随后，基于数据类型鉴别模块的熵值分析结果，识别出由指数位高位组成的、具有高度冗余的位平面（即图~\ref{fig:float_binary}中的红色区域），构成\textbf{冗余集中区}。这个区域呈现出由相似部分构成的循环排列，包含了大量频繁出现的短字节序列，因此可以被通用压缩算法高效处理。对于熵值较高的非冗余区（如尾数位），则直接跳过压缩，避免无效计算。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{../figures/模型数据处理模块.drawio.pdf}
    \bicaption{模型数据处理模块}{Model data processing module}\label{fig:model_data_processing}
\end{figure}

\subsection{细粒度子块匹配方法}
非模型数据块（如文本、日志、代码）通常在版本迭代中仅发生微小修改，因此不同数据块之间，尤其是在大块数据中，存在大量局部重复内容。为有效利用此种冗余，本文设计了专门的非模型数据处理模块，如图~\ref{fig:non_model_data_processing}所示。

该模块首先对非模型数据块进行\textbf{细粒度哈希处理}：将大块数据进一步拆分为更小的子块，并通过滚动哈希为每个子块计算唯一指纹，作为数据块的细粒度特征。随后，\textbf{相似块查找器}查询细粒度特征索引，识别出与当前块具有部分相同细粒度特征的相似块。通过比较二者的指纹序列，可以快速找出所有匹配的子块。

对于匹配的子块，系统将其视为冗余，仅保存指向参考块及其偏移量的元数据指针；对于不匹配的子块，则经由通用压缩算法压缩后存储。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{../figures/非模型数据处理模块.drawio.pdf}
    \bicaption{非模型数据处理模块}{Non-model data processing module}\label{fig:non_model_data_processing}
\end{figure}

与传统的块级去重相比，该模块能更深入地挖掘块内冗余。与增量压缩相比，该方法在计算效率上更具优势：特征提取采用高效的滚动哈希，冗余去除则通过指纹比较快速定位并跳过整个冗余子块，避免了字节级的差分计算所需的大量开销。通过这种优化的设计，系统能够在保持较低计算成本的同时，实现对大块数据局部重复的高效识别与处理。

\section{存储去重工作流}
在详细介绍系统的总体设计与各模块原理之后，本节将进一步阐明系统在处理存储请求时的具体工作流，以便于理解其实际运行过程及数据在各模块间的流转与变化。如图~\ref{fig:system_dedup_workflow}所示，系统的存储去重工作流涵盖了从数据接收、初步去重、数据类型鉴别、细粒度冗余处理，直至最终数据存储的完整闭环。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{../figures/系统去重存储工作流.drawio.pdf}
    \bicaption{系统去重存储工作流}{System deduplication storage workflow}\label{fig:system_dedup_workflow}
\end{figure}

工作流始于\textbf{读取与分块}阶段。原始文件（例如，一个包含 AAA、BBB、CCC、DDD 和 MODEL\footnote{MODEL 部分数据段为模型数据，其余为非模型数据} 数据段的文件）被读入系统，数据流经由切块器分割为若干固定大小的数据块。此步骤将连续的数据流转化为离散的、易于管理的处理单元，为后续的精细化操作奠定基础。

紧接着进入\textbf{块级去重}阶段。系统通过哈希引擎为每个数据块（如 AAAA、BBBB、CCCC、DDDD）计算唯一指纹，并查询全局指纹索引。此阶段旨在快速消除全局范围内完全一致的重复块。如图所示，数据块 AAAA 和 CCCC 的指纹在索引中被找到，因此被判定为重复块，系统仅保留指向已存储数据的元数据指针；而块 BBBB、DDDD 和 MODEL 块作为唯一块，则进入下一处理阶段。此环节显著减少了需要进一步处理的数据量。

系统的核心创新体现在\textbf{类型鉴别与数据路由}阶段。所有唯一块被送入数据类型鉴别模块。该模块基于数据内容特征进行块级分析，将数据块精确地判别为“模型数据块”或“非模型数据块”，并据此将数据送入不同的处理路径。具体而言：
\begin{itemize}
    \item \textbf{模型数据路径}：被识别的 MODEL 块进入模型数据处理模块。在此，系统通过专用编码算法（针对浮点数指数位高位的编码重组），将原始块的指数位集中排列。这一变换本身并不缩减数据大小，而是通过重组数据结构，将一个不可压缩的数据块转化为一个可压缩的数据块。
    \item \textbf{非模型数据路径}：被识别的传统数据块（如 BBBB、DDDD）则进入非模型数据处理模块。该模块启动细粒度去重流程，首先进行细粒度哈希，将大块进一步分解，生成细粒度特征（如 b、b, d、d）。随后，通过查询细粒度特征索引，发现块 BBBB 的细粒度特征 b、b 与索引中的 b、l 存在部分匹配。通过依次比对细粒度特征，系统识别出 BBBB 和已存储块 BBLL 之间的连续冗余部分（BB），并仅保存指向参考块及其偏移量的元数据指针，而非直接存储冗余内容。对于剩余的不匹配子块，则经由通用压缩算法压缩后存储。
\end{itemize}

最后是\textbf{压缩与持久化}阶段。所有经过差异化处理的数据单元，包括来自模型路径的编码块、来自非模型路径的差异块和唯一块，被统一送入压缩模块，由通用压缩算法（如 LZ4、Zstd）进行最终处理，以消除剩余的统计冗余。处理完毕的数据块被组织进容器，并与更新后的指纹索引、细粒度特征索引等元数据一同写入持久化存储，完成整个工作流。
\section{本章小结}
本章针对现有重复数据删除系统在处理现代云存储工作负载时所面临的挑战，提出了一种面向混合负载的细粒度冗余识别重复数据删除系统（FHRD）。

该系统通过引入数据类型鉴别模块，实现了对模型数据块与非模型数据块的精确区分，从而能够针对不同类型的冗余数据设计并实施差异化的处理策略。对于模型数据块，系统采用专门的编码算法以有效消除数值冗余；对于非模型数据块，则通过细粒度哈希与相似块查找技术，实现对大块数据局部重复内容的高效识别与处理。整体架构在设计上充分考虑了计算效率与系统性能，确保在显著提升去重效果的同时，严格控制计算与存储开销。

最后，本章通过对系统存储去重工作流的详细阐述，清晰地展示了各模块如何协同工作，以及数据在处理过程中的具体变化，为后续章节的性能评估与实验验证奠定了坚实的基础。

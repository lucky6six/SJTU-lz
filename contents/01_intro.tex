% !TEX root = ../main.tex

\chapter{绪 论}


\section{研究背景与意义}
云计算技术的成熟与普及，深刻地重塑了现代信息技术产业的格局。作为其三大核心服务（IaaS、PaaS、SaaS）的共同基石，云存储系统承担着为全球海量用户提供可靠、
可扩展数据存储能力的核心使命。它通过虚拟化技术将海量异构的物理存储设备抽象为一个统一、弹性的逻辑资源池，为用户提供按需分配、动态伸缩、高可用且持久化的数据存储能力，
实现了计算与存储的解耦，显著提升了资源利用率和系统部署的灵活性，已成为现代企业数据管理的关键支撑。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/01云存储服务系统架构.drawio.pdf}
    \bicaption{云存储服务系统架构}{System architecture for cloud storage services}
    \label{fig:cloud_storage_architecture}
\end{figure}

从技术架构的视角审视，典型的云存储系统（如图~\ref{fig:cloud_storage_architecture} 所示）普遍采用分层设计。底层是由 HDFS、Ceph 等构成的分布式存储基础层，负责数据的物理存储与高可用保障；中间是存储服务层，负责将物理资源封装为对象存储、文件存储等服务，并集成去重、压缩、计量等功能；顶层则是面向用户的应用接口层。

随着数字化转型浪潮席卷各行各业，以及大数据、人工智能等技术的广泛应用，全球数据总量正以前所未有的速度爆炸式增长。企业级应用、个人存储、物联网设备及科学计算等场景，每时每刻都在向云端注入海量数据，使得存储成本成为云服务提供商最主要的运营支出之一~\cite{khan2024cloud}。



为了有效应对大规模数据带来的成本压力，\textbf{数据缩减 （Data Reduction）}技术成为云存储系统中不可或缺的核心技术~\cite{dubois2011key}。这些技术在数据写入物理介质前，
通过智能识别并消除冗余信息，从而显著降低实际存储占用和网络传输开销。其中，\textbf{块级去重（Block-level Deduplication）}技术与\textbf{通用压缩（Compression）}技术因其普适性和有效性而得到广泛应用。
总体技术范式可概括为：首先，将连续的数据流切割成若干数据块；然后，为每个数据块计算唯一的密码学哈希值（如SHA-256）作为其“指纹”；最后，通过比对全局指纹库识别重复数据块，仅存储指向已有数据的元数据指针，
而对新数据块则压缩后存入物理介质~\cite{xia2016comprehensive}。这套“切块—指纹—去重—压缩”的技术体系，在过去以文档、代码、虚拟机镜像等传统数据为主的时代取得了巨大成功，为云存储的规模化与商业化奠定了坚实的技术基础。




然而，近年来云存储数据缩减效率遇到瓶颈，这与其所承载的工作负载变化密切相关。
其一，为追求高 I/O 吞吐，现代存储系统倾向于采用更大的数据块尺寸，
MB 级别的数据块在分布式生产环境中已屡见不鲜~\cite{borthakur2008hdfs}。
对于尺寸日益增大的传统数据块，传统去重技术的效果也显著下降~\cite{pengburst}。
将数据块从 KB 级提升至 MB 级，极大地降低了找到两个完全相同大数据块的概率。
尽管这些大块内部往往包含大量局部重复片段（如重复的日志、代码或文档段落），但传统以整个块为
单位的粗粒度去重对此类“局部连续冗余”视而不见，导致去重能力下降。这揭示了数据缩减系统需要更细粒度的冗余识别。


其二，随着人工智能，特别是深度学习技术的突破性进展，AI 应用催生了以 \texttt{.pt}、\texttt{.safetensors} 等格式保存的模型参数文件，
其体积动辄达到数百 GB 甚至 TB 级别，在总存储容量中的占比急剧攀升~\cite{wang2026zipllm}。对于海量的 AI 模型数据，传统去重与压缩技术几乎同时失效。

\begin{itemize}
    \item \textbf{去重失效}：模型文件由亿万级相互独立的浮点数张量构成，数据内容呈现高度的随机性和唯一性。
    当系统将其切分为数据块时，几乎每个块都会拥有一个独一无二的指纹，这使得基于全局指纹匹配的去重机制完全失效，去重率趋近于零。
    \item \textbf{压缩失效}：诸如LZ4、Zstandard等通用压缩算法，其核心原理是寻找并消除字节序列层面的重复模式。
    然而，模型数据的冗余并非体现在连续的字节流中，而是源于浮点数的数值分布特征与内部结构。具体而言，在32位单精度浮点数中，
    其二进制表示由符号位、指数位和尾数位构成。在训练好的模型中，绝大部分权重参数的数值集中在某个较小区间内（例如[-2, 2]），
    导致其指数位的前几位高度相似甚至完全相同。此外，由于量化或模型结构带来的规律性，字节层面可能呈现以2字节或4字节为周期的“循环相似”模式。
    这种由高位重复、数值分布集中所构成的“数值冗余”，是传统字节级压缩算法难以捕捉和利用的~\cite{hershcovitch2025zipnn}。
\end{itemize}
% 一方面，模型文件由浮点数张量构成，
% 数据内容呈现高度随机性，使得基于全局指纹匹配的块级去重机制完全失效。另一方面，通用压缩算法旨在寻找字节序列的重复，
% 而模型数据的冗余源于浮点数的数值分布与内部结构——即指数位高位的高度相似性，
% 这种“数值相似性冗余”是传统字节级压缩算法无法捕捉的~\cite{hershcovitch2025zipnn}。

综上所述，这两种负载变化趋势共同塑造了“模型数据与大块数据共存”的混合负载新常态。
当前云存储数据缩减技术面临的困境，其症结在于传统技术的冗余识别“粒度”与新兴数据特征不匹配。
无论是大尺寸传统数据中存在的“局部连续冗余”，还是混杂的模型数据中隐含的“数值冗余”，都超越了传统块级指纹比对技术的感知范围。
因此，突破这一瓶颈的关键路径在于，从“块级”的粗放式处理，迈向“细粒度冗余识别”的新范式。

然而，一个严峻的挑战随之而来：这两种细粒度冗余的类型、结构与产生机理截然不同，导致为单一场景设计的优化算法在混合数据流中会相互干扰，
产生“负优化”效应。例如，将专为提取数值冗余设计的编码器用于文本数据，会因破坏其原有结构而降低压缩率。反之，专为发现文本数据块内部局部重复而设计的算法，对模型数据则完全无效，
同时增加了不必要的元数据存储和计算开销。因此，简单堆砌多种优化算法的方案变得不可行，开发一个能够智能识别并协同处理多种冗余模式的统一框架，成为突破当前技术瓶颈的关键。


基于此，本研究提出并构建了一套名为 FHRD (Fine-grained Hybrid Redundancy Data Reduction) 的细粒度冗余识别数据缩减系统。
其核心思想是构建一个统一的、细粒度的数据处理框架。该框架首先在传统去重流水线的基础上，增加了块内连续冗余识别能力，通过对数据块内部的细粒度划分对比，去除局部重复片段。
其次，该框架内置一个轻量级的、基于内容的冗余模式鉴别模块，它能实时、准确地判别数据块所蕴含的冗余类型是否符合模型数据规律。
随后，框架根据鉴别结果，采用专用的分组编码方法压缩模型数据的数值冗余。通过这种协同处理架构，FHRD 能够在不显著影响系统吞吐性能的前提下，对数据施加最有效的优化手段，从而系统性地提升混合负载下的整体数据缩减率。

\section{国内外研究现状}
%这一节拿取一些第二章的内容
数据去重与压缩技术的研究已历经数十年的发展，从传统的块级去重到细粒度的冗余识别，再到针对特定数据类型的专用压缩，技术路径呈现出不断细化与深入的趋势。

%\textbf{内容定义切块（Content-Defined Chunking）}的
传统块级去重技术是云存储系统中数据缩减的基石，其核心原理是通过消除重复数据块来降低存储开销。
根据切块策略的不同，主要分为固定大小切块与可变长度切块两种技术路线。固定大小切块方案将数据流均分为固定长度的块，实现简单，
性能开销可控，但存在明显的边界效应——数据在切块边界处的微小变化会导致后续所有切块都不匹配，严重降低去重效率~\cite{quinlan2002venti}。
为克服这一局限，可变长度切块技术应运而生，它利用Rabin指纹等滚动哈希算法，根据数据内容本身动态确定切块边界，
使切块结果对数据插入和删除操作更具弹性~\cite{muthitacharoen2001low}。然而，无论是固定还是可变切块，
它们都依赖于寻找完全相同的字节序列，对于AI模型文件中普遍存在的数值相似性冗余，传统方法完全无法识别。
同时，为提升I/O吞吐而采用的MB级大数据块，也使得块内大量存在的局部连续重复无法被检测和消除。

在块级去重之后，通用压缩算法，如Gzip \cite{gailly1992gnu}、LZW \cite{nelson1989lzw}、ANS \cite{duda2015use}，作为数据缩减流水线的第二道工序，负责进一步消除数据块内部的统计冗余。近年来，压缩算法的研究主要围绕速度与压缩率的平衡展开，
产生了如LZ4\footnote{\url{https://github.com/lz4/lz4}} 和Zstandard~\cite{collet2018zstandard}等新一代压缩算法。LZ4以其极致的压缩和解压速度著称，适合实时
高吞吐场景，但压缩率相对较低。Zstandard则致力于在速度与压缩率间取得更优平衡，通过引入有限状态熵编码（FSE）和预训练字典等机制，
提供了灵活的压缩级别选择，在保持高速解压的同时实现了接近甚至超越传统Gzip的压缩率。尽管这些通用压缩算法对文本类数据表现出色，
但它们对AI模型数据的压缩效果极为有限，其根本原因在于它们基于字节序列重复模式进行压缩，无法捕获模型数据内在的数值冗余。

% \subsection{细粒度冗余识别技术}

为突破传统块级去重在大块场景下的局限，学术界提出了多种细粒度冗余识别技术，主要可分为两大
类：面向相似块的增量压缩技术和面向局部连续重复的细粒度去重技术。增量压缩技术旨在通过识别数据块间的相似性，
仅存储差异部分（Delta）来实现压缩。其核心挑战在于如何快速、准确地从海量数据块中找出相似块对。从早期的N-Transform~\cite{broder1997resemblance}到
Finesse~\cite{zhang2019finesse}和Odess~\cite{xia2023design}，研究者们不断优化特征提取与匹配算法
以平衡精度与效率。找到相似块后，Xdelta~\cite{macdonald2000file}和Gdelta~\cite{tan2024design}等差异编码技术则用于
生成紧凑的补丁文件。另一研究方向专注于消除大块数据内部的局部连续重复，Burst~\cite{pengburst}是这方面的典型代表。它通过在MB级大
块内部进行识别并消除首尾长重复序列，有效缓解了因块尺寸增大导致的去重率下降问题。然而，这些细粒度技术在带来更高去重率的同时，
也引入了额外的计算开销和系统复杂性，在混合负载环境中若不加区分地应用，可能导致资源浪费。

% \textbf{网络剪枝}（Pruning）旨在通过移除神经网络中的冗余参数来压缩模型。
% \begin{itemize}
%     \item \textbf{非结构化剪枝}：移除单个不重要的权重，通常依据权重大小或对损失函数的影响来判断。虽然灵活，但可能导致不规则的稀疏矩阵，不利于硬件加速。
%     \item \textbf{结构化剪枝}：在更高粒度上（如神经元、通道或层）进行操作，保持了网络的规整结构，便于在通用硬件上高效推理。
% \end{itemize}

% \textbf{模型量化}（Quantization）通过降低权重和激活值的数值精度来压缩模型并加速计算。
% \begin{itemize}
%     \item \textbf{训练后量化}（Post-Training Quantization, PTQ）：无需重新训练，直接对已训练好的 FP32 模型进行量化。实现简单，但可能带来精度损失。
%     \item \textbf{量化感知训练}（Quantization-Aware Training, QAT）：在训练过程中模拟量化效应，使模型能够适应低精度表示，通常能取得更好的性能。
% \end{itemize}
面对AI模型数据的独特性，研究者提出了多种专用压缩技术，其中量化和剪枝是最为重要的两种方向。
模型量化~\cite{gholami2022survey}通过降低权重和激活值的数值精度来减少存储与计算开销，而模型
剪枝~\cite{ma2021effective}则通过移除冗余参数来实现模型压缩。但这两类方法属于有损压缩且严重依赖模型训练过程，通常不适用于要求
数据完整性的云存储服务。此外，还涌现了如ZipNN~\cite{hershcovitch2025zipnn}、FM-Delta~\cite{ning2024fm}和ZipLLM~\cite{wang2026zipllm}等无损压缩方法，它
们利用模型权重间的数值分布规律或跨模型版本的比特级相似性，实现了比通用算法更高的压缩率。但这些方法往往只针对特定格式的模型文件，
无法处理打包文件或识别模型文件中的非模型部分（如文件头、量化内容），限制了其在真实备份场景中的应用。

综上所述，当前数据缩减技术研究面临三大挑战。
首先，混合负载下的适配问题尚未得到很好解决。专为单一场景设计的优化方案在混合数据流中可能相互干扰，产生负优化~\cite{wang2026zipllm}。
其次，现有细粒度冗余识别技术虽提升了去重率，但其计算开销和系统复杂性仍是广泛应用的障碍。
第三，模型专用压缩技术在追求高压缩率的同时，常忽视通用性和系统集成问题，难以适应真实的云存储环境。

\section{本文研究工作与主要贡献}
块级去重技术和通用压缩技术在应对新兴的混合工作负载时效能急剧下降。本研究深入分析发现，
问题的本质在于传统技术体系与新兴数据特征之间的“粒度失配”——
传统粗粒度冗余识别方法难以利用大尺寸传统数据内部的局部连续重复模式，也无法有效捕捉AI模型数据中的数值相似性冗余。
更为严峻的是，针对单一数据类型优化的先进技术（如面向模型数据的专用压缩和面向传统数据的细粒度去重）
在混合负载环境下会产生相互干扰，导致整体性能下降。这一发现揭示了当前研究领域的一个重要空白：
缺乏一个能够智能区分数据类型并自适应应用最优缩减策略的统一框架。

基于此，本研究的核心任务是设计并实现一套面向混合负载的细粒度冗余识别系统，旨在解决三个关键问题：
（1）如何设计并实现细粒度块内冗余的高效去重，以应对数据大块化的挑战；
（2）如何设计并实现模型数据的数值冗余识别与压缩方法，突破传统数据缩减技术的瓶颈，以应对日益增多的模型数据；
（3）如何实现各种优化策略的协同工作，避免混合场景下的相互干扰，并在不显著影响系统吞吐的前提下，提升整体数据缩减率。

为解决上述问题，本文创新性地提出了名为FHRD (Fine-grained Hybrid Redundancy Deduplication) 的细粒度冗余识别数据缩减系统架构。如图3-1所示，该系统在传统数据缩减流水线的基础上，引入了数据类型鉴别层和差异化处理层，形成了模块化、可扩展的系统架构。数据块经过冗余模式鉴别探针进行快速类型分析；基于鉴别结果，系统将数据块路由至相应的处理模块；最后，处理完成的数据与元数据一同存储。

本文的工作和贡献主要体现在以下几个方面：

\begin{enumerate}
    \item 揭示了云存储下的负载的大块化，模型化，混合化趋势。系统性地分析了传统数据缩减技术在现代云存储环境中失效的根源，明确了两种影响显著的新型冗余：模型数据中的“数值冗余”与大块传统数据中的“局部连续冗余”，并阐述了它们的特征与分布规律。

    \item 通过局部子块的指纹计算与匹配，定位并消除大块数据的局部连续冗余，有效缓解了因块尺寸增大导致的去重率下降问题。

    \item 提出了基于内容特征的高精度块级数据类型鉴别方法，将模型数据的处理从原有流程中剥离。该方法克服了依赖文件元数据进行模型数据识别的局限性，其核心创新在于发现了模型数据在字节层面呈现的“循环相似模式”，并设计了相应的轻量级检测算法。与现有方法相比，该鉴别机制具有精度高、适用性广的优势，且能够准确识别出模型文件中的非模型部分（如文件头、量化内容），避免了误用专用编码器导致的负优化。

    \item 设计并整合了面向混合场景的差异化冗余处理逻辑。分离了模型数据的处理流程，针对其的数值冗余，基于浮点数位结构分析，重组高度相似的指数位部分，将不可压缩数据块转化为可压缩形式；实现了对模型冗余的精准优化与整体去重效能的提升。

    \item 实现并优化了完整的原型系统，进行了系统性的实验验证。本研究基于开源去重系统Destor \cite{fu2015design}实现了FHRD原型。实验结果表明，在混合负载下，FHRD相比传统方法在去重率上取得了20\%至30\%的显著提升。我们通过全面的实验，涵盖了不同模型数据比例、块大小配置及文件形式，详细分析了各模块的性能特征和系统整体开销，为混合负载下的数据缩减提供了有力的评估数据。
\end{enumerate}

\section{论文结构}
本文内容共分为六章，其组织结构如下：

第一章为绪论。阐述研究背景与意义，分析云存储在人工智能时代面临的新挑战，指出传统数据缩减技术在混合负载下的局限性。在此基础上，明确本文的研究目标与主要创新点，并概述论文的组织结构。

第二章为相关工作。系统回顾并对比分析数据去重、通用压缩、细粒度冗余识别及模型专用压缩等方向的代表性工作。通过归纳现有方法的适用场景与不足，为本文方法的设计动机提供理论与实证依据。

第三章为系统设计。针对现有技术的痛点，提出面向混合负载的FHRD系统总体架构。首先分析细粒度冗余特征，明确系统设计目标；继而详细阐述“块级数据类型鉴别”模块、模型数据编码方法及非模型数据细粒度子块匹配方法的设计；最后梳理系统工作流，为后续实现奠定基础。

第四章为系统实现与优化。聚焦系统落地过程中的核心挑战，给出具体的实现与优化方案。详细介绍字节粒度分组抽样熵值分析、基于熵值结论的字节分组压缩、指数取整的双向子块定长切分等核心方法的实现细节；同时，为提升系统整体性能，设计了数据段聚合、多级索引缓存及流水线并行处理等优化策略。

第五章为实验评估。搭建标准化实验平台，选取多样的非模型、模型及混合负载数据集，设置多种对照方案，从去重率、吞吐量、鉴别准确率等核心指标展开全面评估。通过基准实验、消融实验和参数敏感性实验，系统地验证FHRD在混合负载下的整体优势、各关键模块的贡献及其在不同场景下的适应性。

第六章为总结与展望。系统总结全文研究成果，提炼FHRD系统的核心技术创新与工程实践价值。同时，分析当前研究的局限性，并结合存储技术发展趋势，对未来的研究方向进行展望。

% Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor
% incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis
% nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
% Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu
% fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in
% culpa qui officia deserunt mollit anim id est laborum.

% \section{脚注}
% Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor
% incididunt ut labore et dolore magna aliqua. \footnote{Ut enim ad minim veniam,
% quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
% consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum
% dolore eu fugiat nulla pariatur.}

% \section{字体}

% 上海交通大学是我国历史最悠久的高等学府之一，是教育部直属、教育部与上海市共建的全
% 国重点大学，是国家“七五”、“八五”重点建设和“211 工程”、“985 工程”的首批建
% 设高校。经过 115 年的不懈努力，上海交通大学已经成为一所“综合性、研究型、国际化”
% 的国内一流、国际知名大学，并正在向世界一流大学稳步迈进。 


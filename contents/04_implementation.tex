% !TEX root = ../main.tex

\chapter{系统实现与关键技术}

第三章详细阐述了系统的总体架构、核心流程以及各模块的设计理念。然而，在将这些理论设计转化为实际可运行的系统时，仍然面临诸多工程挑战。本章将深入探讨系统的具体实现细节与关键优化技术，内容涵盖核心功能的落地难点、实现架构、工作流程及类设计等方面，并重点突出系统在实际运行中的性能优化与资源管理策略。

\section{系统实现挑战}
本系统基于第三章所设计的细粒度去重架构，并遵循模块化设计思想，将各项关键功能解耦为独立模块进行实现。系统整体架构如图~\ref{fig:FHRD_architecture}所示。

在实现层面，本系统以开源的传统重复数据删除系统 Destor\footnote{https://github.com/fomy/destor} 为基础，在其上扩展实现了数据类型鉴别、模型数据指数位冗余识别与压缩、非模型数据块内连续冗余去除等核心功能，并集成了 Zstandard (Zstd) 压缩模块，最终构建了一个面向混合负载、支持细粒度冗余识别与去除的高效重复数据删除系统。在将设计方案落地为具体实现的过程中，我们主要面临以下挑战：

\begin{enumerate}
    \item \textbf{高效准确的数据类型鉴别}：系统需要在不引入过多计算开销的前提下，准确识别出以 BF16 和 FP32 为代表的、具有浮点数指数位相似模式的模型数据。然而，按位遍历整个数据块来寻找循环相似规律的计算成本过高，难以满足性能要求。
    \item \textbf{模型数据的冗余区域识别}：系统需要有效定位模型数据中的指数高位，以便将这部分冗余集中起来进行针对性处理。但实际切块过程中，系统无法感知浮点数的具体格式，甚至可能将一个浮点数切分到两个数据块中，导致数据不对齐问题。
    \item \textbf{非模型数据的子块划分}：为了有效去除不同数据块间的连续重复区域，系统需要对非模型文件进行高效的子块划分和特征提取。然而，现代块级去重系统普遍采用内容定义切块（CDC）以规避边界偏移问题，这导致生成的数据块长度不一。若简单地对变长块进行均匀切分，将难以保证子块的一致性，从而影响重复区域的识别效果。
    \item \textbf{数据管理与缓存策略}：细粒度去重引入了额外的计算与存储开销，系统必须设计高效的数据管理和索引缓存策略，以应对这些新增的性能压力。
    \item \textbf{数据块结构重构}：在传统去重流程的基础上，系统集成了多个细粒度处理阶段及通用压缩模块。因此，必须对数据块的存储结构进行重构，以容纳新增的细粒度元信息，并明确指示解压或解码方式。
    \item \textbf{并行处理策略}：为充分利用多核处理器的计算能力，提升细粒度去重的处理速度，系统需要设计一套高效的并行处理策略。
\end{enumerate}


\section{数据类型鉴别：字节粒度的分组抽样熵值分析}
为了有效识别模型数据，系统需要检测各比特位的熵值以衡量其相似性，从而定位浮点数的指数位。然而，直接在比特粒度上进行操作存在两大难题。首先，对整个数据块进行频繁的位操作会显著增加实现的复杂性和计算开销。其次，如果采用抽样方式计算熵值，小样本中的某些比特位可能因偶然性而表现出较低的熵值，从而导致误判，如图~\ref{fig:bitwise_complexity}所示。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.1.1.drawio.pdf}
    \bicaption{比特粒度实现的复杂性}{Complexity of bit-level implementation}\label{fig:bitwise_complexity}
\end{figure}

为解决此问题，我们通过分析不同类型的模型数据，发现其浮点数的冗余和表示形式具有明确的规律性：
\begin{enumerate}
    \item \textbf{数值冗余规律}：参考图~\ref{fig:d}和图~\ref{fig:float_binary}，可以发现存在去重空间的模型数据块，其冗余主要集中在指数高位。这些高位表现出极高的相似度，即较低的熵值。从模型训练的角度看，归一化层将激活值约束在零均值、单位方差的分布附近，使得绝大多数数值落在有限范围内（如 [-1, 1]）。随着模型收敛，权重更新幅度减小，数值分布更趋集中。在浮点数表示中，这种特性直接体现为指数部分的高位比特保持稳定，而尾数位则承载着随机性较强的精度信息。因此，指数高位的低熵特性是模型收敛稳定性与数值标准化处理在存储层面的直接映射。
    \item \textbf{表示形式规律}：如图~\ref{fig:float_representation}所示，训练过程中产生的、存在数值冗余的模型文件，其浮点数格式主要为 FP32、BF16 和 FP16。在这三种表示方法中，指数高位恰好完整地分布在某个字节内部，构成低熵字节。同时，这三种浮点数的长度分别为 4 字节或 2 字节，这意味着数据块中的低熵字节会以 4 字节（FP32）或 2 字节（BF16/FP16）的周期重复出现。
\end{enumerate}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.1.2.drawio.pdf}
    \bicaption{模型浮点数的表示形式}{Representation of model floating-point numbers}\label{fig:float_representation}
\end{figure}

基于上述规律，我们提出了一种\textbf{字节粒度的分组抽样熵值分析方法}，以实现高效、准确的数据类型鉴别。如图~\ref{fig:bytewise_entropy}所示，该方法首先对数据块进行抽样，每个抽样点相对于块头的偏移量均为 4 的整数倍。然后，将抽样数据按字节逐一分为 4 组，并分别计算每组字节的熵值。最后，系统根据熵值分布情况判断数据块类型：
\begin{itemize}
    \item 若出现一组低熵字节组和三组高熵字节组，则判定为 FP32 类型的模型数据块。
    \item 若出现两组低熵字节组，且组索引之差为 2，则判定为 BF16 或 FP16 类型的模型数据块。
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.1.3.drawio.pdf}
    \bicaption{字节粒度的分组抽样熵值分析}{Byte-wise grouped sampling entropy analysis}\label{fig:bytewise_entropy}
\end{figure}

与原设计相比，该实现方法具有以下优点：
\begin{enumerate}
    \item \textbf{实现简单}：字节粒度的处理避免了复杂的位操作，简化了实现难度，提升了鉴别过程的计算效率。
    \item \textbf{高效准确}：通过字节分组，利用指数高位在字节内的集中特性，形成了显著的低熵字节组，而其他部分则构成高熵字节组。这种设计有效避免了因采样过小而导致的尾数位偶然低熵对鉴别结果的干扰，从而显著降低了误判率，并允许在保证精度的前提下进一步缩减采样点数量，降低计算开销。
\end{enumerate}



\section{基于熵值分析结论的字节分组压缩}
模型数据处理模块的目标是识别并集中模型数据块中数值相似的浮点数指数位，以便利用通用压缩算法进行数据缩减。与图~\ref{fig:bytewise_entropy}的流程类似，该模块对整个模型数据块按字节进行拆分，分为 4 组，从而将指数位数据集中在特定组内，形成可压缩的冗余部分。

然而，由于数据块切分的盲目性，系统既无法预知浮点数的具体类型，也无法保证其在数据块中的对齐，甚至可能将一个浮点数切分到两个数据块中。因此，系统难以直接确定哪一组是指数位所在组。若像鉴别阶段一样重新计算分组熵值，将因处理整个数据块而产生巨大的计算开销。ZipNN 等相关工作选择对所有组进行压缩，但这会引入对非冗余高熵组的无效压缩运算。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.2.drawio.pdf}
    \bicaption{基于熵值分析的字节分组压缩}{Byte-wise grouped compression based on entropy analysis}\label{fig:byte_group_compression}
\end{figure}

如图~\ref{fig:byte_group_compression}所示，本文提出了一种\textbf{基于熵值分析结论的字节分组压缩方法}，以高效识别指数位所在组并进行针对性压缩。系统在鉴别阶段已经计算出各组的熵值分布，并获得了低熵字节组的索引，该索引实际上指明了浮点数指数位所在字节相对于数据块的偏移量。因此，在模型数据处理阶段，系统可以直接复用这一结论，仅提取并压缩低熵字节组，从而显著提升压缩效率。与盲目压缩所有组的方法相比，该方法对 32 位数据块缩减了 75\% 的压缩输入，对 16 位数据块缩减了 50\% 的压缩输入。


\section{指数取整的双向子块切分}
针对大块数据内部的连续冗余，本文受到 Burst 方法对首尾连续冗余识别的启发，提出通过提取数据子块的特征来代表连续子块内容，并通过匹配相同特征来识别连续冗余区域。然而，Burst 采用的固定长度切块无法有效应对边界偏移问题。现代块级去重系统普遍采用基于内容的切块方法，以确保数据块边界与实际内容对齐，但这导致了数据块长度不一，为子块划分带来了新的挑战。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.3.1.drawio.pdf}
    \bicaption{定长切块的边界偏移问题}{Boundary offset problem in fixed-length chunking}\label{fig:boundary_offset}
\end{figure}

定长切块会引发边界偏移问题。传统数据（如文本、日志、代码）在修改后常会产生副本，二者间往往仅在中间存在少量变化，而大部分内容保持不变，如图~\ref{fig:boundary_offset}所示。但在定长切块中，即使仅在中间插入或删除少量数据（如图中加粗斜体所示），后续所有切块的边界都会发生偏移（如图中黄色部分所示），导致无法匹配到重复块。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.3.1.1.drawio.pdf}
    \bicaption{变长切块解决边界偏移问题}{Variable-length chunking solves the boundary offset problem}\label{fig:variable_length_chunking}
\end{figure}

基于内容定义的变长切块方法可以有效解决此问题。通过内容哈希确定切块边界，使得插入或删除数据后，未受影响的内容仍能被正确切分为相同的数据块，从而实现重复数据的识别与去除，如图~\ref{fig:variable_length_chunking}所示。

然而，变长切块在解决边界偏移问题的同时，也给子块划分带来了挑战。由于变长切块产生的数据块长度不一，若简单地将数据块按固定份数均分，则无法保证子块大小的一致性，难以匹配冗余区域，如图~\ref{fig:fixed_length_chunking}所示。图中相似数据块仅在红色区域有修改，但均分子块无法匹配。若采用定长子块划分，则会在块内重新引入边界偏移问题，且固定的子块长度可能不适用于各种长度的变长块。若采用内容定义的变长子块切分，则会引入额外的计算开销，影响系统性能。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.3.2.drawio.pdf}
    \bicaption{固定份数为 3 的子块划分}{Sub-block division into 3 fixed parts}\label{fig:fixed_length_chunking}
\end{figure}

基于上述考量，本文提出了一种\textbf{指数取整的双向子块定长切分方法}，以高效地将变长数据块划分为定长子块，同时缓解边界偏移问题。

具体而言，系统首先根据变长数据块的长度，计算出最接近且不大于该长度 1/10 的 2 的幂次方，作为该块的子块长度。在大小相近的相似块中，该子块长度通常为相同的定值，避免了类似图~\ref{fig:fixed_length_chunking}中的问题。同时，由于子块长度适应性地设定为 2 的幂次方，能够较好地适应不同长度的数据块，避免了过大或过小的子块划分。

然后，系统从数据块的起始和结束位置分别向中间方向，以该子块长度进行定长切分，得到若干子块，并计算其哈希指纹作为特征。在相似块的冗余匹配过程中，也同时进行双向特征值匹配，如图~\ref{fig:exponential_rounding_chunking}所示。根据 Burst 等相关研究，相似块的修改通常集中在中间的连续区域。因此，这种双向切分方法能够在一定程度上缓解边界偏移问题，因为即使数据块在中间部分发生了插入或删除，双向匹配仍能识别出相同的子块，从而定位连续的冗余区域。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.3.3.drawio.pdf}
    \bicaption{指数取整的双向子块定长切分方法}{Exponential rounding bidirectional sub-block fixed-length segmentation method}\label{fig:exponential_rounding_chunking}
\end{figure}



\section{数据管理与缓存优化}
细粒度去重流程引入了额外的计算和存储开销，因此系统采用了高效的数据管理和索引缓存策略以提升整体性能。系统通过数据段（Segment）在逻辑上聚合相邻数据块，并通过容器（Container）在物理存储上管理临近数据块，二者协同工作以提升 I/O 局部性与批处理效率。同时，系统设计了多级索引缓存策略，以减少对底层存储的随机访问次数和索引查找延迟。

\subsection{局部聚合的数据块批处理}
随着存储规模的持续增长，单个数据块的随机 I/O 和逐一索引查找所带来的开销愈发显著。为此，系统将数据流按逻辑邻近性划分为若干数据段（Segment），每个数据段代表一组“相邻”的数据块，既作为预取的单位，也作为批处理的基本粒度。

一方面，当发现某个数据块重复或相似时，其同一数据段内的其他块很可能也具有相同或相似的属性。以数据段为单位预取对应的容器或索引条目，可以显著减少随机读次数与索引查找延迟，从而提升 I/O 局部性与缓存命中率。

另一方面，将数据按数据段聚合后作为批量单元传递给后续模块（如去重、重写与写容器），可以将多次对单块的重复访问合并为一次批处理操作，从而降低每个数据块的平均 I/O 与计算开销，并提高整体吞吐量与并行效率。

\subsection{基于容器的磁盘信息管理}
与数据段管理类似，容器（Container）是系统的基本物理存储单元，它将若干去重后的数据块按一定策略打包并持久化到后端存储。容器兼具数据布局与元数据管理两项职责。

首先，容器通过将相邻或逻辑相关的多个块聚合到同一个写入单元，提升了写入的顺序性，减少了系统对底层介质的每块随机写入与读回次数，从而降低了每个块的随机 I/O 开销。

其次，容器保存了必要的元信息（如每个块的偏移、长度、校验和，以及块指纹到容器内偏移的映射），以便在后续的读取操作中快速定位与检索块数据。同时，可以基于容器级别的预取策略一次性缓存相关容器或其索引条目，将对单块的随机读转化为对整个容器（或容器元索引）的少量顺序读，从而大幅降低随机访问与底层索引查找的成本。

\subsection{多级索引缓存策略}
为了应对细粒度去重带来的额外索引查找开销，系统采用了多层次的索引缓存策略，如图~\ref{fig:multi_level_index_cache}所示，以提升索引查找效率，减少对底层存储的随机访问次数与延迟。
\begin{figure}[htbp]
    % \centering
    \includegraphics[width=1.4\textwidth]{../figures/0409.pdf}
    \bicaption{多级索引缓存下的匹配查找时序}{Matching lookup timing with multi-level index cache}\label{fig:multi_level_index_cache}
\end{figure}

最底层是磁盘中的键值（KV）索引存储，负责存储数据指纹或特征到容器位置的映射关系。在此之上，系统设计了两级内存缓存：
\begin{itemize}
    \item \textbf{一级缓存（全局缓存）}：采用 LRU（最近最少使用）策略保存最常用的数据指纹或特征的映射关系，并以容器为单位从底层存储预取数据，以提升整体缓存命中率。
    \item \textbf{二级缓存（局部缓存）}：以数据段为单位保存当前正在处理的、尚未落盘的容器内的数据指纹或特征的映射关系，以减少对底层存储的随机访问次数与索引查找延迟。
\end{itemize}

此外，由于系统采用流水线并行处理，可能存在已完成去重处理但尚未落盘的容器。这部分容器对应的指纹或特征映射尚未在全局缓存中更新，但又可能超出了局部缓存的范围。因此，介于二者之间，系统还设计了\textbf{临时索引缓存}，以避免重复计算与查找。当存储线程将容器落盘后，会更新全局缓存，并清理临时索引缓存中的对应条目（详见 4.6 节对流水线并行的描述）。

在一次重复块匹配或相似块查找的过程中，系统会依次查询局部缓存、临时索引缓存和全局缓存。若均未命中，则访问底层的 KV 存储，并以容器为单位更新全局缓存。




\section{数据块重构}
为了支持细粒度去重，系统对数据块的结构进行了重构，增加了新的元信息以指示解压/解码方式并存储细粒度信息，如图~\ref{fig:data_block_structure}所示。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.3\textwidth]{../figures/0410数据块结构.drawio.pdf}
    \bicaption{数据块结构}{Data block structure}\label{fig:data_block_structure}
\end{figure}

其中，\texttt{size} 字段表示数据块的原始大小，\texttt{data} 指向数据块内容。
\texttt{features} 字段仅在数据块类型为 MATCH 时生效，用于存储细粒度特征信息，即存储两个指向双向子块特征数组的指针。
\texttt{block\_type} 字段表示数据块的类型（如唯一块 UNIQUE、重复块 DEDUP、模型块 MODEL、非模型匹配块 MATCH 等）。
\texttt{container\_id} 字段表示数据块所在的容器标识，而数据块在容器内的偏移位置则由容器元数据管理。
\texttt{fingerprint} 字段存储数据块的哈希指纹，用于唯一标识数据块内容。
\texttt{ref\_info} 字段存储冗余差分信息，包含基准块 ID 以及基准块子块特征与本数据块的匹配情况。以图~\ref{fig:exponential_rounding_chunking}为例，记录匹配子块索引为 1、2、-1（负值表示反向子块索引）。具体的子块偏移量可以通过子块大小和索引计算得出，而子块大小则可根据 4.4 节中描述的方法由 \texttt{size} 字段计算得到。
\texttt{model\_info} 字段仅在数据块类型为 MODEL 时生效，用于存储模型数据的熵值分析结论，即低熵字节组的索引。正值表示 16 位浮点数的指数位组索引为 \texttt{model\_info} 和 \texttt{model\_info}+2，负值则表示 32 位浮点数的指数位组索引为 -\texttt{model\_info}。
\texttt{compress\_type} 表示去重后数据的压缩方法和预期的解压缩方法，默认为 0，表示 ZSTD 压缩，其他值可扩展为其他压缩算法。





\section{数据去重流水线并行}
为了提升系统的整体处理性能，本文在整个端到端流程中引入了流水线并行的处理方式。具体实现参考图~\ref{fig:system_dedup_workflow}，图中每个蓝色圆角矩形代表一个处理阶段，每个阶段均由不同的线程并行处理，线程间的数据通信则通过全局队列实现。具体流程如下：

\begin{itemize}
    \item \textbf{读取（Read）线程}：将待存储数据源分割为数据流，并推入 \texttt{read\_queue}，供下一阶段并行消费。
    \item \textbf{切块（Chunk）线程}：从 \texttt{read\_queue} 读取数据，通过内容定义切块方式进行切分，为每个数据块生成元数据（块大小、位置指针等），并聚合成段（Segment）后送入 \texttt{handler\_queue}。
    \item \textbf{哈希（Hash）线程}：以段为粒度从 \texttt{handler\_queue} 获取数据，计算每个数据块的哈希指纹，填充段内各块的元数据，并更新数据索引。
    \item \textbf{去重（Dedup）线程}：按顺序对每个块检查四层缓存或索引（如 4.5 节所述），检测其是否为重复数据块，并更新相应元数据，将其 \texttt{block\_type} 标记为 DEDUP。
    \item \textbf{鉴别（Identify）线程}：对队列中所有 \texttt{block\_type} 不为 DEDUP 的数据块进行类别鉴别（如 4.2 节所述），将模型数据块的 \texttt{block\_type} 标记为 MODEL，并更新其低熵索引元数据。
    \item \textbf{模型编码（Model Encode）线程}：对标记为 MODEL 的模型数据块进行基于熵值分析结论的字节分组压缩（如 4.3 节所述）。
    \item \textbf{非模型数据处理模块}：
    \begin{itemize}
        \item \textbf{细粒度哈希（Fine-hash）线程}：对非 MODEL 数据块完成双向切块和特征提取（如 4.4 节所述），并更新数据块的细粒度特征元数据。
        \item \textbf{细粒度去重（Fine-dedup）线程}：依据细粒度特征元数据，查找 4.5 节所述的缓存索引结构，匹配相似数据块，并通过子块匹配去除局部重复冗余。
        \item \textbf{冗余差分（Diff）线程}：提取非冗余区域，并记录在块的元信息中。
    \end{itemize}
    \item \textbf{压缩（Compress）线程}：从 \texttt{handler\_queue} 中读取需要写入的原始数据，包括编码后的模型块、局部去重后的差异块以及唯一块。对这些数据块进行压缩后，推入 \texttt{save\_queue}。
    \item \textbf{存储（Save）线程}：将最终需要写入的压缩数据块聚合到容器（Container）中，更新缓存和文件结构元信息，并清理临时索引缓存中的对应条目。
\end{itemize}

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.8\textwidth]{../figures/流水线并行.png}
%     \bicaption{数据去重流水线并行时序}{Data deduplication pipeline parallelism timing}\label{fig:pipeline_parallelism}
% \end{figure}




\section{实现侵入性分析}
本节从三方面分析本系统设计对已有块级去重流水线的侵入性：集成灵活性、可配置性以及性能影响与缓解策略。目标是在尽量不破坏原有流程和接口的前提下，提供可插拔、可调优的细粒度去重能力，方便在不同部署场景中权衡吞吐、延迟与去重收益。

% \subsection{集成灵活性}
模块化与流程隔离：系统以模块化形式新增数据鉴别、模型编码与细粒度处理等功能模块，这些模块在逻辑上位于传统块级去重与压缩之间。
默认情况下，原有的读/切块/哈希/去重/压缩/写入流程保持不变；当开启细粒度功能时，仅将“唯一块”通过队列传递给鉴别模块并在处理后返回压缩模块。
该设计保证了对原流程的最小侵入性：未启用时不改变已有数据路径，启用时仅在必要路径插入处理。


% \subsection{可配置性}
为了兼顾不同工作负载与部署资源，系统将关键策略参数化，可在运行时或通过配置文件调整：
\begin{itemize}
    \item 切块相关：是否开启内容定义切块（CDC）或使用固定切块；变长块最小/最大阈值；双向子块划分的子块最小比例（例如：1/10）与指数取整策略。默认：保留原有系统的 CDC 配置，细粒度子块长度按 1/10 并向下取最近的 2 的幂。
    \item 鉴别策略：采样率（抽样字节数/块）、抽样偏移步长（4 字节对齐默认）、熵判定阈值与最小采样点数；允许将鉴别算法切换为“保守”“平衡”“激进”三档以控制误判率与计算开销。默认：“平衡”档。
    \item 模型编码/处理：是否对所有组进行压缩或仅压缩低熵组；对 16/32 位识别的优先级；压缩前是否先进行字节重组。默认：仅压缩鉴别出的低熵组。
    \item 非模型子块策略：子块最小/最大大小、哈希窗口与滚动哈希步长，以及双向匹配的最大偏移容忍度。默认：子块长度按章节中描述的指数取整策略，滚动哈希步长为字节对齐。
    \item 压缩后端与并行度：可选择 ZSTD/LZ4/无压缩等。默认：ZSTD（默认级别）。
    \item 缓存策略：本地 Feature Cache 大小、LRU 驱逐参数、临时索引缓存失效时间等。默认：可用内存按比例配置。
\end{itemize}

以上参数均以配置文件或运行时接口暴露，便于在不同场景下快速调优以平衡压缩收益与性能开销，也方便实现不同对照组比较优化效果。

% \subsection{性能影响分析与缓解}
系统在引入细粒度去重功能的同时，尽量减小对整体吞吐与延迟的影响。主要考虑以下两个方面：

运算方面：额外的细粒度处理流程引入计算开销，通过以下优化策略缓解：
\begin{itemize}
    \item 细粒度鉴别（熵计算、抽样）：通过字节粒度分组，减少位操作复杂度，并降低了抽样数据量以降低计算量。
    \item 模型编码（分组压缩）：利用鉴别阶段的熵值结论，避免对非冗余高熵组的无效压缩运算，减少 50\%--75\% 的压缩输入。
    \item 非模型子块划分（双向定长切分）：通过指数取整的定长切分，避免了内容定义子块划分的高计算开销，同时缓解边界偏移问题。
    \item 流水线并行处理：通过多线程流水线设计，充分利用多核处理器资源，提升整体处理吞吐，尽可能掩盖细粒度处理的延迟开销。
\end{itemize}

内存方面：细粒度特征存储与索引增加了内存使用，通过以下优化策略缓解：
\begin{itemize}
    \item 多级缓存策略：通过局部缓存、临时索引缓存与全局缓存的协同工作，减少对底层存储的随机访问次数与延迟。
    \item 数据段与容器管理：通过数据段聚合与容器化存储，提升 I/O 局部性与批处理效率，降低每块的随机 I/O 开销。
\end{itemize}


\section{本章小结}
本章详细阐述了细粒度冗余识别的重复数据删除系统的具体实现细节与优化方法。首先，分析了系统实现过程中面临的关键挑战，
包括高效准确的数据类型鉴别、模型数据冗余区识别、非模型数据子块划分等方面。随后，介绍了系统的整体实现架构与工作流程，
并重点突出各关键设计的落地优化细节，如字节粒度的分组抽样熵值分析、基于熵值分析结论的字节分组压缩、指数取整的双向子块切分方法、多级索引缓存策略、
数据块结构重构以及流水线并行处理等。最后，分析了系统设计对已有块级去重流水线的侵入性，强调了其集成灵活性、可配置性以及性能影响与缓解策略。
通过本章的实现与优化，系统在实际运行中能够高效识别与去除细粒度冗余数据，
为后续的性能评估与实验提供了坚实的基础。
% !TEX root = ../main.tex

\chapter{细粒度冗余识别的重复数据删除系统实现与优化}
第3章介绍了系统的总体架构与流程，以及各模块的原理与设计思路，但在实际的系统实现中，相关设计的落地仍然面临着许多问题与挑战。
本章中将一步阐述系统的具体实现细节与优化方法。内容涵盖各关键设计的落地挑战，实现架构、工作流程以及类设计等方面，
重点突出系统在实际运行中的性能优化和资源管理策略。

\section{系统实现挑战}
将第3章所设计的细粒度去重流程实现在实际系统中，面临着以下挑战：

1.高效准确的数据类型鉴别：系统需要在不引入过多计算开销的前提下，准确识别多种类型的模型数据（包括BF16和FP32）
所代表的浮点数指数位相似模式。然而按位遍历数据块寻找循环相似规律过于耗时。

2.模型数据的冗余区识别：系统需要能够有效地识别出模型数据中指数高位的位置，
从而将这部分冗余集中，以便进行针对性的优化和处理。然而实际系统切块时无法感知到浮点数格式，
甚至可能将一个浮点数切分到两个数据块中，即数据不对齐。

3.非模型数据的子块划分：系统需要能够对非模型文件进行有效的子块划分和特征提取，以便去除不同数据块中的连续重复区域。
然而，为了规避边界偏移问题，现代块级去重系统通常采用基于内容的分块方法，以确保数据块的边界与实际数据内容对齐，得到长度不一的数据块。
若简单地将数据块均分，将影响重复区域的识别效果，难以得到相同子块。


4.数据管理与缓存策略：系统需要设计高效的数据管理和索引缓存策略，以应对细粒度去重带来的额外计算和存储开销。

5.数据块结构重构：系统在传统去重层基础上引入了若干细粒度去重流程，并添加了通用压缩模块。因此系统需要修改数据块的存储结构，以存储细粒度信息，并指示解压/解码方式。

6.并行处理策略：系统需要设计高效的并行处理策略，以充分利用多核处理器的计算能力，提升细粒度去重的处理速度。

\section{系统实现概述}
本系统基于第3章所设计的细粒度去重架构，采用模块化设计思路，将各关键功能划分为独立模块进行实现。系统整体架构如图3.4所示。

系统基于开源的传统重复数据删除系统destor\footnote{https://github.com/fomy/destor}，实现了数据类型鉴别、模型数据指数位冗余识别与压缩、非模型数据块内连续冗余去除等功能，并
集成了ZSTD压缩模块。从而实现了一个面向混合负载的、支持细粒度冗余识别与去除的高效重复数据删除系统。

系统采用C作为开发语言，主要考虑以下因素：

1. C语言具有高效的性能和对底层系统资源的良好控制能力，适合实现高性能的存储去重系统。

2. C语言在系统编程领域有广泛的应用，拥有丰富的库和工具支持，便于实现复杂的功能，也便于集成到传统去重系统中。

3. C语言的跨平台特性使得系统能够在不同的操作系统和硬件平台上运行，提升了系统的适用性，利于应用在云存储平台。

此外，为了顺利集成到传统流程中并提高系统性能，系统对相关新流程进行了细节优化，重构了数据块，
设计了高效的数据管理与缓存策略，采用了流水线并行的处理，以应对细粒度去重带来的额外计算和存储开销。
具体优化细节将在章节4.3中详细介绍。

\section{系统实现优化}
\subsection{数据类型鉴别：字节粒度的分组抽样熵值分析}
\subsubsection{比特粒度的实现复杂性}
系统需要检测各比特位的熵值以衡量其相似性，从而识别模型数据中的浮点数指数位，判定其为模型数据块，如图4.1所示。

然而，一方面，对整个数据块进行频繁的位操作处理会显著增加实现的复杂性和计算开销。另一方面，若抽样计算熵值，小样本中
某些比特位可能恰好表现出低熵值，导致误判。
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.1.1.drawio.pdf}
    \caption{比特粒度的实现复杂性示意图}
    \label{fig:bitwise_complexity}
\end{figure}

\subsubsection{可去重模型数据分析}
因此，本文通过分析不同类型的模型数据，发现其浮点数的数据冗余和表示形式存在一定的规律性。具体而言，

数值冗余规律：参考图3.3和图3.5，可以发现存在去重空间的模型数据块，其冗余集中在指数高位，该指数高位表现出较高的相似度，即较低的熵值。
从模型训练的角度分析其原理，训练中的归一化层将激活值约束在零均值、单位方差的分布附近，使得绝大多数数值在有限范围内（如[-1,1]）；
随着模型收敛，权重更新幅度逐渐减小，数值分布更趋集中。在浮点格式中，这种分布特性直接体现为指数部分的高位比特保持稳定，
而尾数位则承载随机性较强的精度信息。这种指数高位的低熵特性，本质上是模型收敛稳定性和数值标准化处理在存储层面的直接映射。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.1.2.drawio.pdf}
    \caption{模型浮点数表示形式示意图}
    \label{fig:float_representation}
\end{figure}

表示形式规律：如图4.2所示,训练过程中产生的存在数值冗余的模型文件，浮点数格式主要有FP32，BF16和FP16三种形式。而在这三种形式的表示方法中：

1.指数高位恰好存在于最后一字节内部，组成低熵值字节。

2.这三种浮点数长度为2字节或4字节，即数据块中该低熵值字节以2字节（BF16/FP16）或4字节（FP32）的频率出现。


\subsubsection{字节粒度的分组抽样熵值分析方法}
基于上述结论，本文提出了一种字节粒度的分组抽样熵值分析方法，以实现高效准确的数据类型鉴别。
如图4.3所示，系统首先对数据块进行抽样，每个抽样点相对于块头的偏移量均为4字节的整数倍。然后，
将抽样数据按字节进行划分，逐字节分为4组，分别计算每组字节的熵值。最后，系统根据熵值分布情况，判断数据块是否为模型数据块。
具体而言，若出现一组低熵值字节组，三组高熵值字节组，则判定该数据块为FP32类型的模型数据块。若出现两组低熵值字节组，且组索引差值为2，则判定该数据块为BF16或FP16类型的模型数据块。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.1.3.drawio.pdf}
    \caption{字节粒度的分组抽样熵值分析示意图}
    \label{fig:bytewise_entropy}
\end{figure}


该实现方法相较原设计有以下优点：

1.实现简单：字节粒度的处理避免了复杂的位操作，简化了实现难度，提升鉴别过程的计算效率。

2.高效准确：通过字节分组，利用指数高位的连续集中特性，组成了低熵值字节组，
其余部分组成高熵值字节组，避免因采样过小导致偶然的尾数位低熵值影响鉴别结果，从而减少误判率。
相对应的可以进一步缩减采样点数量，降低计算开销。



\subsection{模型数据处理：基于熵值分析结论的字节分组压缩}




模型数据处理模块的目标是识别出模型数据块中数值相似的浮点数指数位所在的位置，从而将这部分集中，以便利用通用压缩算法进行数据缩减。

与图4.3的流程类似同理，该模块对整个模型数据块进行数据拆分，逐字节分为4组。从而将指数位数据集中在某一组中，形成可压缩的冗余部分。

然而，由于数据块切分的盲目性，系统既不能感知到浮点数的具体类型，也无法确保浮点数在数据块中的对齐性，甚至可能将一个浮点数切分到两个数据块中。
因此系统并不知道哪一组才是浮点数的指数位所在组，而若像鉴别阶段一样计算分组熵值，则会产生额外的计算开销，且该阶段不再是抽样，而是需要对整个数据块进行处理，计算量更大。


\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.2.drawio.pdf}
    \caption{基于熵值分析的字节分组压缩示意图}
    \label{fig:byte_group_compression}
\end{figure}

zipNN等方法选择对所有组进行压缩，引入了对非冗余高熵组的无效压缩运算。如图4.4所示,本文提出了一种基于熵值分析结论的字节分组压缩方法，
以高效识别指数位所在组并进行压缩。具体而言，系统在鉴别阶段已经得到了各组的熵值分布情况，并得到了低熵值字节组的索引，该索引实际代表了浮点数指数位所在字节相对于数据块的偏移量。
因此在模型数据处理阶段，系统可以直接利用鉴别阶段的熵值分析结论，针对性地提取低熵值字节组并进行压缩，从而提高压缩效率。
相对于盲目地对所有组进行压缩，该方法对32位数据块缩减了75\%的压缩输入，对16位数据块缩减了50\%的压缩输入。


\subsection{非模型数据处理：指数取整的双向子块切分}

受到burst对首尾连续冗余的识别消除启发，本文提出提取数据子块特征代表连续子块内容，通过
匹配相同特征来识别连续冗余区域的方法。然而，burst方法采用固定长度切块，难以应对边界偏移问题。
现代块级去重系统通常采用基于内容的分块方法，以确保数据块的边界与实际数据内容对齐，得到长度不一的数据块，这
对子块划分提出了新的挑战。

\subsubsection{边界偏移问题}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.3.1.drawio.pdf}
    \caption{定长切块边界偏移问题示意图}
    \label{fig:boundary_offset}
\end{figure}

定长切块会带来边界偏移问题。传统数据（如文本、日志、代码等）常常在修改（如插入、删除或替换字符）后得到另一份副本，二者间常常仅在中间存在少量变化，而大部分内容保持不变，如图4.5所示。
但在定长切块中，即使仅在中间插入或删除少量数据（图中加粗斜体），后续所有切块的边界都会发生偏移，如图中黄色部分，导致无法匹配到重复块。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.3.1.1.drawio.pdf}
    \caption{变长切块解决边界偏移问题示意图}
    \label{fig:variable_length_chunking}
\end{figure}

基于内容定义的变长切块方法可以有效解决边界偏移问题，通过内容哈希确定切块边界，使得插入或删除数据后，未受影响的内容仍能被正确切分为相同的数据块，从而实现重复数据的识别与去除，如图4.6所示。


\subsubsection{变长切块带来的子块划分挑战}
变长切块解决了边界偏移问题，但也带来了子块划分的挑战。

变长切块得到的数据块长度不一，若简单地将数据块按固定份数均分，则无法保证
子块大小的一致性，难以匹配冗余区域，如图4.7所示，相似数据块仅有红色区域有修改，但均分子块无法匹配。

若采用定长子块划分方法，则会在块内产生新的边界偏移问题，且该定长可能并不适合各种长度的变长块。

若采用内容定义的变长子块切分方法，则引入额外的计算开销，影响系统性能。


\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.3.2.drawio.pdf}
    \caption{固定份数为3的子块划分示意图}
    \label{fig:fixed_length_chunking}
\end{figure}
\subsubsection{指数取整的双向子块定长切分方法}


基于上述考量，本文提出了一种指数取整的双向子块定长切分方法，以高效划分变长数据块为定长子块，同时缓解边界偏移问题。

具体而言，系统首先根据该变长数据块长度，计算出最接近且不大于数据块长度1/10的2的幂次方，作为该块的子块长度。在大小相近的相似块中，该子块长度为相同的定值，避免了类似图4.7中的问题。
同时，在不同数据块间，由于该子块长度适应性地设定为2的幂次方，能够较好地适应不同长度的数据块，避免过大或过小的子块划分。

然后，系统从数据块的起始位置和结束位置分别向中间方向，以该子块长度进行定长切分，得到若干子块，并计算其哈希指纹作为特征。在相似块的冗余匹配过程中，也同时进行双向特征值匹配，如图4.8所示。
根据burst等的相关研究，相似块的修改通常集中在中间的一段连续区域。因此，这种双向的切分方法，能够在一定程度上缓解边界偏移问题，因为即使数据块在中间部分发生了插入或删除，
双向匹配仍能识别相同子块，从而识别出连续冗余区域。


\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/4.3.3.3.drawio.pdf}
    \caption{指数取整的双向子块定长切分方法示意图}
    \label{fig:exponential_rounding_chunking}
\end{figure}



\subsection{数据管理与缓存优化}
细粒度去重流程引入了额外的计算和存储开销，系统采用了高效的数据管理和索引缓存策略，以提升整体性能。

具体而言，系统通过数据段（segment）在逻辑上聚合相邻数据块，而容器（container）在物理存储上管理临近数据块。
二者协同工作，提升I/O局部性与批处理效率。同时，系统设计了多级索引缓存策略，以减少对底层存储的随机访问次数与索引查找延迟。




\subsubsection{局部聚合的数据块批处理}

随着存储规模的持续增长，单个数据块的随机 I/O 和逐一索引查找开销变得越来越显著。为此，系统将数据流按逻辑邻近性划分为若干数据段（segment）：每个数据段表示一组“相邻”的数据块，既作为预取的单位，也作为批处理的基本粒度。

一方面，在发现某个数据块重复或相似时，其同一数据段内的其它块很可能也具有相同或相似的属性；以数据段为单位预取对应的容器或索引条目，可以显著减少随机读次数与索引查找延迟，提升 I/O 局部性与缓存命中率。

另一方面，把数据按数据段聚合后作为批量单元传递给后续模块（例如去重、重写与写容器），可以把多次对单块的重复访问合并为一次批处理操作，从而降低每个数据块的平均 I/O 与计算开销，并提高整体吞吐与并行效率。


\subsubsection{基于容器的磁盘信息管理}

与数据段管理类似，容器（container）是系统的基本物理存储单元：
它把若干个去重后的数据块按一定策略打包成一个容器并持久化到后端存储。
容器兼具数据布局与元数据管理两项职责。

首先，容器通过把相邻或逻辑相关的多个块聚合到同一个写入单元，提升写入顺序性，减少系统对底层介质的每块随机写入与读回次数，减少每个块的随机 I/O 开销；

其次，容器保存必要的元信息（例如每个块的偏移、长度、校验与块指纹到容器内偏移的映射），以便在后续的读取
操作中快速定位与检索块数据。同时，可以基于容器级别的预取策略一次性缓存相关容器或其索引条目，从而把对
单块的随机读转化为对整个容器（或容器元索引）的少量顺序读，从而大幅降低随机访问与底层索引查找的成本。



\subsubsection{多级索引缓存策略}
为了应对细粒度去重带来的额外索引查找开销，系统采用了多层次的索引缓存策略如图所示，以提升索引查找效率，减少对底层存储的随机访问次数与延迟。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1.1\textwidth]{../figures/缓存索引时序图.png}
    \caption{多级索引缓存下的匹配查找时序图}
    \label{fig:multi_level_index_cache}
\end{figure}



最底层是磁盘中的KV索引（KV store）存储，存储数据指纹或特征到容器位置的映射关系。

在此之上，系统设计了两级内存缓存：

一级是全局缓存（feature cache），以LRU的缓存驱逐策略保存最常用的数据指纹或特征的映射关系，以容器为单位从
底层存储预取数据，提升整体缓存命中率。

二级是局部缓存（container buffer），以数据段为单位保存当前处理的、尚未落盘的容器内的数据指纹或特征的映射关系，
以减少对底层存储的随机访问次数与索引查找延迟。

此外，由于系统采用流水线并行处理，可能存在已去重处理但未落盘的容器，这部分容器对应的指纹或特征映射尚未在全局缓存中
更新，但又有可能超出局部缓存的范围。因此，介于二者之间，系统还设计了临时索引缓存（index buffer），以避免重复计算与查找。
当save线程将容器落盘后，更新全局缓存，并清理临时索引缓存中的对应条目。详见4.3.6中对流水线并行的描述。

在一次重复块匹配或相似块查找的过程中，系统依次查询局部缓存、临时索引缓存和全局缓存，
若均未命中，则访问底层KV存储，以容器为单位更新全局缓存。




\subsection{数据块重构}

系统对数据块结构进行了调整，以增加新的元信息以指示解压/解码方式，存储细粒度信息，如图4.9所示。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.6\textwidth]{../figures/数据块结构.drawio.pdf}
    \caption{数据块结构示意图}
    \label{fig:data_block_structure}
\end{figure}

其中，size字段表示数据块的原始大小，data指向待存储数据块内容。
block type字段表示数据块的类型（如唯一块UNIQUE、重复块DEDUP、模型块MODEL、非模型匹配块MATCH等），
container id字段表示数据块所在的容器标识，数据块在容器内的偏移位置由容器元数据管理。
fingerprint字段表示数据块的哈希指纹，用于唯一标识数据块内容。features字段只在数据块类型为MATCH时生效，
在用于存储细粒度特征信息，即存储两个指向双向子块特征数组的指针。ref info字段存储冗余差分信息，包含基准块id，以及基准块子块特征与本数据块的匹配情况，
以图4.8距离，记录匹配子块索引为1，2，-1（负值表示反向子块索引），具体的子块偏移量可以通过子块大小和子块索引计算得到，
子块大小可按4.3.3.3中计算方法，由size字段得到。model info字段只在数据块类型为MODEL时生效，存储模型数据的熵值分析结论，即低熵值字节组的索引。
正值表示16位浮点数的指数位组索引为modelinfo和modelinfo+2，负值表示32位浮点数的指数位组索引为 -model info。compress type表示去重后数据的
压缩方法和预期的解压缩方法，默认为0，表示ZSTD压缩，其他值可扩展为其它压缩算法。





\subsection{数据去重流水线并行}
为了提升系统的整体处理性能，本文在整个端到端流程中引入了流水线并行的处理方式。
具体实现方式参考图3.9，图中每个蓝色圆角矩形表示一个处理阶段，每个阶段都由不同的线程并行处理，线程间的数据通信通过全局队列实现。

具体而言，读取（read）线程把待存储数据源分割为数据流，并推入read queue，然后下一阶段并行消费。

切块（chunk）线程从read queue 读取数据，通过内容定义分块方式切分，为每个数据块生成元数据（块大小，位置指针等），聚合为segment后送到 handler queue。

哈希（hash）线程从handler queue中按segment为粒度获取数据，计算每个数据块的哈希指纹，用其填充segment内blocks的元数据，并更新数据索引。

去重（dedup）线程对每个blocks按顺序检查四层缓存或索引，如4.3.4所述，检测其是否为重复数据块，并更新重复数据块对应元数据，标记其block type位DEDUP。

鉴别（identify）线程对队列中每个block type不为DEDUP的数据块进行如4.3.1所述的类别鉴别，将模型数据块的block type标记为MODEL，并更新其低熵索引元数据。

模型编码（model encode）线程对标记为MODEL对模型数据块进行如4.3.2所述的基于熵值分析结论的字节分组压缩。

非模型数据处理模块中，细粒度哈希（fine-hash）线程非MODEL数据块对完成如4.3.3所述的双向切块和特征提取，并更新数据块细粒度特征元数据；细粒度去重（fine-dedup）线程依据细粒度特征元数据，查找4.3.4所述缓存索引结构，匹配相似数据块，并通过子块匹配去处局部重复冗余；冗余差分（diff）线程，提取非冗余区域，记录在块的元信息中。

随后，压缩线程从handler queue中读取需要写入的原始数据，包含编码后的模型块，局部去重后的差异块，以及唯一块。对这些数据块进行压缩，推入save queue中。

最后，存储（save）线程把最终需要写入的压缩数据块聚合到容器中 （container），更新缓存和文件结构元信息，并清理临时索引缓存中的对应条目。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/流水线并行.png}
    \caption{数据去重流水线并行时序图}
    \label{fig:pipeline_parallelism}
\end{figure}



\section{实现侵入性分析}
本节从三方面分析本系统设计对已有块级去重流水线的侵入性：集成灵活性、可配置性以及性能影响与缓解策略。目标是在尽量不破坏原有流程和接口的前提下，提供可插拔、可调优的细粒度去重能力，方便在不同部署场景中权衡吞吐、延迟与压缩收益。

\subsection{集成灵活性}
模块化与流程隔离：系统以模块化形式新增数据鉴别、模型编码与细粒度处理等功能模块，这些模块在逻辑上位于传统块级去重与压缩之间。
默认情况下，原有的读/切块/哈希/去重/压缩/写入流程保持不变；当开启细粒度功能时，仅将“唯一块”通过队列传递给鉴别模块并在处理后返回压缩模块。
该设计保证了对原流程的最小侵入性：未启用时不改变已有数据路径，启用时仅在必要路径插入处理。


\subsection{可配置性}
为了兼顾不同工作负载与部署资源，系统将关键策略参数化，可在运行时或通过配置文件调整：

\begin{itemize}
    \item 切块相关：是否开启内容定义分块（CDC）或使用固定分块；变长块最小/最大阈值；双向子块划分的子块最小比例（例如：1/10）与指数取整策略。默认：保留原有系统的 CDC 配置，细粒度子块长度按 1/10 并向下取最近的 2 的幂。
    \item 鉴别策略：采样率（抽样字节数/块）、抽样偏移步长（4 字节对齐默认）、熵判定阈值与最小采样点数；允许将鉴别算法切换为“保守”“平衡”“激进”三档以控制误判率与计算开销。默认：平衡档。
    \item 模型编码/处理：是否对所有组进行压缩或仅压缩低熵组；对 16/32 位识别的优先级；压缩前是否先进行字节重组。默认：仅压缩鉴别出的低熵组。
    \item 非模型子块策略：子块最小/最大大小，哈希窗口与滚动哈希步长，以及双向匹配的最大偏移容忍度。默认：子块长度按章节中描述的指数取整策略，滚动哈希步长为字节对齐。
    \item 压缩后端与并行度：可选择 ZSTD/LZ4/无压缩 等。默认：ZSTD（默认级别）。
    \item 缓存策略：本地 feature cache 大小、LRU 驱逐参数、临时索引缓存失效时间等。默认：可用内存按比例配置。
\end{itemize}

以上参数均以配置文件或运行时接口暴露，便于在不同场景下快速调优以平衡压缩收益与性能开销，也方便实现不同对照组比较优化效果。

\subsection{性能影响分析与缓解}

系统在引入细粒度去重功能的同时，尽量减小对整体吞吐与延迟的影响。主要考虑以下两个方面：

运算方面：额外的细粒度处理流程引入计算开销，通过以下优化策略缓解：
\begin{itemize}
    \item 细粒度鉴别（熵计算、抽样）：通过字节粒度分组，减少位操作复杂度，并降低了抽样数据量以降低计算量。
    \item 模型编码（分组压缩）：利用鉴别阶段的熵值结论，避免对非冗余高熵组的无效压缩运算，减少50\%~75\%的压缩输入。
    \item 非模型子块划分（双向定长切分）：通过指数取整的定长切分，避免了内容定义子块划分的高计算开销，同时缓解边界偏移问题。
    \item 流水线并行处理：通过多线程流水线设计，充分利用多核处理器资源，提升整体处理吞吐，尽可能掩盖细粒度处理的延迟开销。
\end{itemize}

内存方面：细粒度特征存储与索引增加了内存使用，通过以下优化策略缓解：
\begin{itemize}
    \item 多级缓存策略：通过局部缓存、临时索引缓存与全局缓存的协同工作，减少对底层存储的随机访问次数与延迟。
    \item 数据段与容器管理：通过数据段聚合与容器化存储，提升 I/O 局部性与批处理效率，降低每块的随机 I/O 开销。
\end{itemize}


\section{本章小结}
本章详细阐述了细粒度冗余识别的重复数据删除系统的具体实现细节与优化方法。首先，分析了系统实现过程中面临的关键挑战，
包括高效准确的数据类型鉴别、模型数据冗余区识别、非模型数据子块划分等方面。随后，介绍了系统的整体实现架构与工作流程，
并重点突出各关键设计的落地优化细节，如字节粒度的分组抽样熵值分析、基于熵值分析结论的字节分组压缩、指数取整的双向子块切分方法、多级索引缓存策略、
数据块结构重构以及流水线并行处理等。最后，分析了系统设计对已有块级去重流水线的侵入性，强调了集成灵活性、可配置性以及性能影响与缓解策略。
通过本章的实现与优化，系统在实际运行中能够高效识别与去除细粒度冗余数据，
为后续的性能评估与实验提供了坚实的基础。
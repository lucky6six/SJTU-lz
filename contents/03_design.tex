% !TEX root = ../main.tex

\chapter{细粒度冗余识别的重复数据删除系统设计}


\section{现有问题分析与设计目标总结}
\subsection{现行传统方案问题分析}
随着模型数据在云存储系统中占据越来越大的比重，以及数据块大小的不断增大，传统重复数据删除系统在处理现代云存储工作负载时暴露出显著的局限性。
具体而言，传统系统主要面临以下几个方面的问题：

（1）对数值冗余的识别能力不足。

传统重复数据删除系统主要依赖于数据块的字节级别匹配来识别冗余数据。然而，现代AI模型文件中大量存在数值冗余，即不同数据块在数值上高度相似但并不完全相同。这种细微的差异使得传统系统难以通过简单的指纹匹配来识别出这些冗余数据，导致去重效果大打折扣。
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/系统去重率随模型数据比例变化情况.pdf}
    \bicaption{系统去重率随模型数据比例变化情况}{deduplication rate variation with model data proportion}
    \label{fig:b}
\end{figure}

在负载为多次修改的文件数据（非模型数据）和transformer模型的多个checkpoints（模型数据）时，开源块级去重系统destor + zstd压缩算法的去重率\footnote{去重率 = 存储数据原始大小/去重压缩后大小}随模型数据占比变化如~\ref{fig:b}所示。随着模型数据比例的增加，传统系统的整体去重率显著下降，甚至当模型占比为100\%时,去重率降低为1，反映出其在处理模型数值冗余方面的不足。

（2）对大块数据中局部重复的处理能力有限。

随着存储块大小的增加，数据块内部往往包含大量的局部重复内容。传统系统
在进行数据切块时，无法有效捕捉到这些局部重复，导致大量冗余数据未被识别和消除。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/系统去重率随数据块平均大小变化情况.pdf}
    \bicaption{系统去重率随数据块平均大小变化情况}{deduplication rate variation with average data block size}
    \label{fig:c}
\end{figure}

在负载为多个版本的linux系统源码tar包时，开源块级去重系统destor + zstd压缩算法的去重率随数据块平均大小变化如图~\ref{fig:c}所示。随着数据块平均大小的增加，传统系统的整体去重率显著下降，反映出其在处理大块数据局部重复方面的不足。

（3）存储和计算开销较高。

为了提高去重效果，传统系统往往需要采用更复杂的切块和指纹计算方法，这增加了系统的
存储和计算开销，影响了系统的整体性能和可扩展性。这也是增量压缩算法等细粒度去重技术难以大规模应用的主要原因。

\subsection{可去重但冗余目标}

这两种场景下传统重复数据删除系统效果下降，但并不意味着这些数据中不存在冗余。相反，这些数据中蕴含着大量的、未能有效识别和处理的冗余，即本文所述细粒度冗余。具体包括：

1. 模型数值冗余：模型指数高位相同、低位略有差异的数值冗余，这种冗余在模型文件中普遍存在，传统的字节级别匹配方法难以捕捉。

如图~\ref{fig:d}所示为transformer模型文件切片中BF16浮点数各bit位熵值\footnote{衡量该位的不相似程度，数据越集中，熵值越低，0表示该位bit值完全为0或完全为1}分布情况，可以看出9-14位的指数位熵值远低于尾数位，表明这些位存在大量冗余（实际上就是图中白色部分）\cite{shannon2001mathematical}，而传统的去重方法无法有效利用这些冗余进行压缩。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/模型文件中BF16浮点数各bit位熵值.pdf}
    \bicaption{模型文件中BF16浮点数各bit位熵值}{bit entropy values of BF16 floating-point numbers in model files}
    \label{fig:d}
\end{figure}

2. 大块非模型数据的局部重复：在大块数据中，往往存在大量的局部重复内容，即使整体数据块不同，但其中的某些部分可能是相同或高度相似的。这种局部重复同样难以被传统的切块和指纹计算方法有效捕捉。



\subsection{现有优化方案问题局限性}
针对上述问题，研究者提出了多种优化方案，主要包括增量压缩技术和专用的模型压缩方法。

finesse，odess等系统引入并优化增量压缩方法，能够更深入地挖掘数据块内部的冗余信息，从而提升去重效果。但是，这些技术通常伴随着较高的计算开销，且在处理模型数据时失效。

专用的模型压缩方法，如ZipNN、ZipLLM和FM-Delta，针对模型数据的特定结构设计，能够实现高效模型压缩。然而，这些方法高度依赖于模型数据的特定格式和结构，只接受模型文件输入，会对非模型数据产生负优化，难以直接应用于混合工作负载的云存储系统中。

上述方法失效的定量分析详见本文第五章。



\subsection{设计目标总结}

基于对现有问题的分析，我们发现在现有重复数据删除系统的基础上，仍有以模型数值冗余和大块数据的局部重复为代表的细粒度冗余未被有效识别和处理。
而现有方法在解决这些问题时，往往面临计算开销高、系统复杂性增加以及适用范围受限等挑战，且针对一种冗余的去重优化会对另一种冗余产生负面影响。
基于此，我们总结出以下设计目标，以指导新型重复数据删除系统的架构设计：

%冗余数据类型鉴别
1. 系统具备数据类型鉴别能力，能够区分不同类型的冗余数据，特指模型数据和非模型数据。从而能够针对模型数值冗余和大块数据局部重复分别处理。

%模型数值冗余识别
2. 系统能够识别模型数据中的数值冗余，设计相应的去重策略，提升去重效果。

%大块数据局部重复识别
3. 系统能够识别非模型数据的局部重复，设计相应的去重策略，提高去重效果。

%计算与存储开销控制
4. 系统能够在保证去重效果的前提下，控制计算与存储开销，不过分影响系统整体性能。

%集成与侵入性控制
5. 系统设计应考虑与现有云存储的传统重复数据删除系统集成与兼容，尽量降低对现有系统的侵入性。


\section{系统总体架构设计}
基于此，我们提出了一种面向混合负载\footnote{混合负载指存储目标中既有模型数据，又有传统的文本、日志、代码等数据}的细粒度冗余识别重复数据删除系统FHRD，系统总体架构如图~\ref{fig:FHRD_architecture}所示。该系统在
传统块级重复数据删除和通用压缩工作流的基础上，集成了多个新模块，为系统赋予数据类型鉴别能力、模型数据数值冗余提取能力和大块数据局部重复识别能力。
其核心在于突破了传统单一去重策略的限制，引入了基于内容的数据类型鉴别机制，并在此基础上实现了“分而治之”的差异化处理流程，针对模型文件的数值冗余和大块数据的局部重复分别进行了专门的去重策略设计与优化。

系统始于存储接口层，该层负责读取配置文件，调整系统参数，然后接收来自上层应用的输入，将待存储文件转化为数据流并暂存于数据缓冲区，为后续处理做好准备。

数据首先经由传统的块级重复数据删除模块进行处理。该模块包含段管理器、文件结构缓存、哈希引擎及重复块查找器等核心组件，负责完成数据分块、指纹计算与初步的全局重复数据查找。其设计与主流工业实践保持一致，确保了系统的基础去重效能与兼容性。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{../figures/细粒度冗余识别的重复数据删除系统总体架构.drawio.pdf}
    \bicaption{细粒度冗余识别的重复数据删除系统总体架构}{overall architecture of fine-grained redundancy-aware deduplication system}
    \label{fig:FHRD_architecture}
\end{figure}

系统的核心创新在于数据鉴别层和细粒度处理层，即图中红色部分。经过传统去重后的唯一数据块，并不会直接进入压缩阶段，而是被送入数据类型鉴别模块。该模块是实现“分治”策略的关键，它通过数据抽样、字节分组、熵值分析等手段，对数据块的底层内容特征进行实时、轻量级的分析，精确判别其为“模型数据块”或“非模型数据块”。

对于被识别出的模型数据块，系统将其路由至模型数据处理模块。该模块深度挖掘浮点数张量中存在的数值相似性冗余（指数位高位重复）。通过数据类型鉴别模块的分组熵值分析结论，识别出指数位所在区域，然后通过重组算法进行编码，将冗余区域集中。从而将不可压缩数据块，变为可部分压缩数据块，有效消除传统方法无法触及的冗余。

对于被识别出的非模型数据块，系统则将其导向非模型数据处理模块。该模块集成了细粒度特征提取引擎与相似块查找器，能够发现相似数据块。而后调用冗余去除器，以子块粒度去除传统大块数据的连续重复冗余，并对剩余的差异量diff进行压缩，实现对传统大块更深层次的去重。

最终，所有处理完毕的数据块（包括经专用编码的模型数据块和经增量压缩后的差异数据）进入持久化存储层。系统通过容器管理策略，将数据及其元数据（包括指纹索引和细粒度特征索引）高效地存入物理存储设备中，完成整个数据处理闭环。

该架构通过流水线集成设计和智能的数据路由，成功地将传统去重、数据类型鉴别、多种细粒度冗余消除技术以及通用压缩算法融合为一个协同工作的整体，显著提升了系统在混合负载场景下的综合数据缩减效率。

\section{混合数据类型鉴别}
\subsection{类型鉴别目标}
数据类型鉴别区分模型数据块和非模型数据块，其最终目的是对模型数据进行专门处理，消除其指数位冗余，而避免对非模型数据块进行不必要的处理，防止负优化。
因此，事实上本文所谓的模型数据块，并非指特定格式（如.safetensors、.pt等）的模型文件，而是指包含大量32位或16位浮点数张量的，在模型训练过程中生成的数据块，这些数据块中的数据内容如图~\ref{fig:float_binary}所示，蕴含着指数位冗余（图中红框内部分），适合进行专门的数值冗余消除处理。
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{../figures/浮点数二进制.png}
    \bicaption{16位浮点数二进制内容}{binary representation of 16-bit floating-point numbers}
    \label{fig:float_binary}
\end{figure}

\subsection{块级鉴别}
基于上述论述，数据包（./tar）、镜像文件（./img）中，可能存在部分模型数据块；而模型权重文件中，也可能包含文件头、量化部分等无上述特点的“非模型数据块”。
因此，文件格式本身作为鉴别依据可能会产生较大的误判可能，必须基于数据内容特征进行分析和鉴别。

\begin{table}[!hpt]
    \bicaption{鉴别粒度对比表}{Comparison of identification granularity}
    \label{tab:comparison_of_identification_granularity}
    \centering
    \begin{tabular}{@{} >{\raggedright\arraybackslash}p{0.3\linewidth}
                                            >{\raggedright\arraybackslash}p{0.3\linewidth}
                                            >{\raggedright\arraybackslash}p{0.3\linewidth} @{}}
        \toprule
        鉴别粒度 & 块级 & 文件级 \\ \midrule
        tar、iso 等打包文件 &
            能识别文件的模型数据部分 &
            全部认为是非模型文件 \\\midrule
        用户自定义非标准后缀的模型文件 &
            能够识别模型数据 &
            无效 \\\midrule
        Q4等没有压缩空间的高熵量化文件&
            可以将其识别为非模型数据 &
            将其作为模型数据进行编码，得到负收益。 \\\midrule
        header 等模型文件中的非模型部分 &
            可以将其识别为非模型数据 &
            将其作为模型数据进行编码，得到负收益。 \\\midrule
        集成侵入性 &
            可以在块处理阶段每块独立进行，对传统块级去重无影响，前序流程可以统一处理。 &
            集成困难 \\
        \bottomrule
    \end{tabular}
\end{table}

因此，本文考虑在块级粒度进行数据类型鉴别。块级鉴别的优点如表~\ref{tab:comparison_of_identification_granularity}所示：

1. 精确识别：块级鉴别能够针对数据块的实际内容进行分析，避免了文件级鉴别可能带来的误判风险。即使在同一文件中，模型数据块和非模型数据块也能被准确区分。

2. 灵活适应混合负载：块级鉴别能够适应包含多种数据类型的混合负载场景，确保每个数据块都能得到适当的处理。

3. 降低负优化风险：通过块级鉴别，系统能够避免对非模型数据块进行不必要的处理，降低负优化的风险，提高整体去重效果。

4. 集成便利性：块级鉴别可以在传统块级去重流程中独立进行，对现有系统的侵入性较低，便于集成和部署。


\subsection{基于分组熵值分析的数据类型鉴别方法}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{../figures/数据类型鉴别模块.drawio.pdf}
    \bicaption{基于分组熵值分析的数据类型鉴别方法}{data type classification method based on grouped entropy analysis}
    \label{fig:data_type_classification}
\end{figure}

如图~\ref{fig:float_binary}所示，模型文件数据块中，浮点数的指数位通常集中在特定的比特位范围内（如16位浮点数的9-14位），这些位的熵值较低，冗余度较高。而非模型数据块则缺乏这种明显的熵值分布特征。
因此，可以通过分析数据块中各比特位的熵值分布，来鉴别数据块的类型。具体方法如图~\ref{fig:data_type_classification}所示：

首先对数据块进行随机抽样，选取若干字节进行分析，降低计算开销。然后循环拆分抽样数据，按位分组，计算组内熵值，得到相似特征。若9-14位熵值显著低于其他位，则判定为16位浮点数模型数据块；同理，若25-30位熵值显著低于其他位，则判定为32位浮点数模型数据块。\footnote{分别对应BF16和FP32格式浮点数的指数高位}若无明显熵值分布特征，则判定为非模型数据块。


\section{数据处理}

\subsection{模型数据编码方法}
模型数据中存在的数值冗余无法被传统通用压缩算法有效识别与处理，其根本原因在于此类冗余的独特分布模式与通用压缩算法的核心工作原理不匹配。
具体而言，模型数据中重复出现的指数位高位虽然在数值逻辑上具有显著的规律性，但在字节流层面，这些承载关键冗余信息的比特并非连续排列，而是分散存储于每个浮点数特定的位中。例如，在32位浮点数序列中，具有相似模式的指数位可能间隔数个字节才出现一次。

通用压缩算法（如LZ系列）的设计初衷是针对字节流中的局部连续性冗余进行优化。这类算法通常基于滑动窗口机制，识别并压缩在固定大小窗口内重复出现的连续字节序列。
然而，模型数据中具有重复模式的指数位在字节层面的“跨度”远小于此类算法所依赖的窗口大小，且其分布具有跨字节的非连续性。因此，通用压缩算法难以捕捉这种分散在不同浮点数间的结构性冗余模式，
无法有效压缩模型数据中的数值冗余，反而会因尝试对高度随机的尾数位进行无效的模式匹配而引入不必要的计算开销，导致“负优化”效应。这一局限性凸显了针对模型数据设计专用处理方案的必要性。

因此，如图~\ref{fig:model_data_processing}所示，本文采用专用编码算法对模型数据块进行处理。该算法首先对数据块中的每个浮点数进行细粒度数据拆分，从而将每位数据集中在一组；而后基于数据类型鉴别模块的熵值分析结果，识别出指数位所在的若干组，这些组（实际上就是图3.5中的红色区域）组成了冗余集中区。该冗余集中区是相似部分的循环排列，具有大量若干字节长度的频繁出现字符串，可以采用通用压缩算法有效消除数值冗余。
对于非冗余区，则跳过压缩处理，避免无效压缩运算开销。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{../figures/模型数据处理模块.drawio.pdf}
    \bicaption{模型数据处理模块}{model data processing module}
    \label{fig:model_data_processing}
\end{figure}

\subsection{细粒度子块匹配方法}
非模型数据块通常包含文本、日志、代码等传统数据类型，这些数据往往存在版本迭代中的微小修改，因此不同数据块之间可能存在大量的局部重复内容，尤其是在大块数据中更为显著。
为了有效识别和消除这些局部重复，本文设计了专门的非模型数据处理模块，如图~\ref{fig:non_model_data_processing}所示。

该模块首先对非模型数据块进行细粒度哈希处理：将大块数据进一步拆分为更小的子块，通过滚动哈希为每个子块计算唯一指纹，作为数据块的细粒度特征。
随后，相似块查找器查询细粒度特征索引，识别出与待存储数据块具有部分相同细粒度特征的相似块。依次比较待存储块和相似块的细粒度指纹，找出匹配的子块。
对于匹配的子块，系统将其作为冗余区域，并不直接存储，而是仅保存指向参考块及其偏移量的元数据指针；对于余下不匹配的子块，经由通用压缩算法压缩后存储。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{../figures/非模型数据处理模块.drawio.pdf}
    \bicaption{非模型数据处理模块}{non-model data processing module}
    \label{fig:non_model_data_processing}
\end{figure}

相较于传统的块级去重方法，该模块能够更深入地挖掘数据块内部的冗余信息。通过对子块级别的相似性进行分析，系统能够识别出那些在整体上不同但局部内容相似的数据块，从而实现更高效的去重效果。

相较于增量压缩方法，该模块在设计上更加注重计算效率和系统性能。
一方面，在特征提取阶段，采用类似块级去重指纹的滚动哈希算法，能够在线性时间完成细粒度特征的计算。
另一方面，在冗余去除阶段，系统依据细粒度特征，快速去除相同子块所代表的连续局部冗余，保存整个差异子块，避免了字节级的差分计算所需的大量计算开销。
通过优化的细粒度哈希算法和高效的相似块查找机制，系统能够在保持较低计算开销的同时，实现对大块数据局部重复的有效识别与处理。

\section{存储去重工作流}

系统的总体设计和各模块原理介绍完成，为便于理解系统的实际运行过程和数据在各模块处理后的变化情况，现进一步阐述系统在处理存储请求时的具体工作流。
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{../figures/系统去重存储工作流.drawio.pdf}
    \bicaption{系统去重存储工作流}{system deduplication storage workflow}
    \label{fig:system_dedup_workflow}
\end{figure}
图~\ref{fig:system_dedup_workflow}所示为系统的存储去重工作流示意图。该工作流涵盖了从数据接收、初步去重、数据类型鉴别、细粒度冗余处理，到最终数据存储的完整过程，具体步骤如下：

工作流始于 “读取与分块”阶段。原始文件（如包含内容为AAA, BBB, CCC, DDD和MODEL\footnote{MODEL部分数据段为模型数据，其余为非模型数据}的数据段）被读入系统，数据流被切块器分成若干数据块。此步骤将连续的数据流转化为离散的、易于管理的处理单元，为后续的精细操作奠定了基础。

紧接着进入 “块级去重”阶段。系统通过Hash引擎为每个数据块（如AAAA, BBBB, CCCC, DDDD）计算唯一指纹，并查询全局指纹索引。此阶段的目标是快速消除全局范围内完全一致的重复块。如图所示，数据块AAAA和CCCC的指纹在索引中被找到，因此被判定为重复块，仅保留元数据指针；而块BBBB、DDDD和MODEL块作为唯一块，进入下一阶段。此环节显著减少了需要进一步处理的数据量。

系统的核心创新体现在 “类型鉴别与分治路由”阶段。所有唯一块被送入数据类型鉴别模块。该模块基于数据内容特征进行块级数据类型鉴别，将数据块精确地判别为“模型数据块”或“非模型数据块”，并实施分治策略：

模型数据路径：被识别的MODEL块进入模型数据处理模块。在此，系统通过专用编码算法（针对浮点数指数位高位的编码重组），将原始块的指数位集中到一起。这一变换本质上不会缩减数据块大小，而是将不可压缩数据块转化为可压缩数据块。

非模型数据路径：被识别的传统数据块（如BBBB, DDDD）则进入非模型数据处理模块。该模块启动细粒度去重流程，首先进行细粒度哈希，将大块进一步分析，生成细粒度特征（如b、b,d、d）。随后，通过查询细粒度特征索引，发现块BBBB的细粒度特征b、b与索引中的b、l匹配。
通过依次匹配细粒度特征，识别BBBB和已存储块BBLL的连续冗余（BB），系统并不直接存储BB，而是仅保存指向参考块及其偏移量的元数据指针；对于余下不匹配的子块BB，经由通用压缩算法压缩后存储。

最后是 “压缩与持久化”阶段。所有经过差异化处理的数据单元，包括来自模型路径的编码块、来自非模型路径的差异块和唯一块，被统一送入压缩模块，由通用压缩算法（如LZ4, Zstd）进行最终处理，以消除剩余的统计冗余。处理完毕的数据块被组织进容器，并与更新后的指纹索引、细粒度特征索引等元数据一同写入持久化存储。
\section{本章小结}

本章针对现有重复数据删除系统在处理现代云存储工作负载时面临的局限性，提出了一种面向混合负载的细粒度冗余识别重复数据删除系统FHRD。

系统通过引入数据类型鉴别模块，实现了对模型数据块和非模型数据块的精确区分，从而能够针对不同类型的冗余数据设计差异化的处理策略。
对于模型数据块，系统采用专用编码算法，有效消除数值冗余；对于非模型数据块，
系统通过细粒度哈希和相似块查找，实现对大块数据局部重复的高效识别与处理。整体架构设计注重计算效率和系统性能，
确保在提升去重效果的同时，控制计算与存储开销。

最后，通过详细阐述系统的存储去重工作流，展示了各模块协同工作的过程，以及数据在各模块处理后的变化情况，为后续章节的性能评估和实验验证奠定了基础。

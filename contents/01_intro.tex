% !TEX root = ../main.tex

\chapter{绪 论}


\section{研究背景与意义}
云计算技术的成熟与普及，有力地推动了现代信息技术产业的发展。云存储系统作为其服务基石之一，承担着为全球海量用户提供可靠、
可扩展的数据存储能力的核心使命。它通过虚拟化技术将海量异构的物理存储设备抽象为一个统一、弹性的逻辑资源池，为用户提供按需分配、动态伸缩、高可用且持久化的数据存储能力，
实现了计算与存储的解耦，显著提升了资源利用率和系统部署的灵活性，已成为现代企业数据管理的关键支撑。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/01云存储服务系统架构.drawio.pdf}
    \bicaption{云存储服务系统架构}{System architecture for cloud storage services}
    \label{fig:cloud_storage_architecture}
\end{figure}

从技术架构的视角审视，典型的云存储系统（如图~\ref{fig:cloud_storage_architecture} 所示）普遍采用分层设计。
底层是由 HDFS、Ceph 等构成的分布式存储基础层，负责数据的物理存储与高可用保障；中间是存储服务层，负责将物理资源封装为对象存储、文件存储等服务，
并集成去重、压缩、计量等功能；顶层则是面向用户的应用接口层。

随着数字化的推进，以及大数据、人工智能等技术的广泛应用，全球数据总量正爆炸式增长。企业级应用、个人存储、物联网设备及科学计算等场景，
每时每刻都在向云端注入海量数据，使得存储成本成为云服务提供商最主要的运营支出之一~\cite{khan2024cloud}。

为了有效应对大规模数据带来的成本压力，\textbf{数据缩减 （Data Reduction）}技术成为云存储系统中不可或缺的核心技术~\cite{dubois2011key}，在数据写入物理介质前，
通过识别并消除冗余信息，从而显著降低实际存储占用和网络传输开销。其中，\textbf{块级去重（Block-level Deduplication）}技术与\textbf{通用压缩（Compression）}技术因其普适性和有效性而得到广泛应用。
总体技术流程可概括为：首先，将连续的数据流切分成若干数据块；然后，为每个数据块计算唯一的密码学哈希值（如SHA-256）作为其“指纹”；最后，通过比对全局指纹库识别重复数据块，仅存储指向已有数据的元数据指针，
而对新数据块则压缩后存入物理介质~\cite{xia2016comprehensive}。这套“分块—指纹—去重—压缩”的技术体系，在过去以文档、代码、虚拟机镜像等传统数据为主的时代取得了巨大成功，为云存储的规模化与商业化奠定了坚实的技术基础。

然而，近年来云存储数据缩减效率遇到瓶颈，这与其所承载的工作负载变化密切相关。
其一，为追求高 I/O 吞吐，现代存储系统倾向于采用更大的数据块尺寸，这导致传统去重技术的效果显著下降~\cite{pengburst}。
因为数据块大小的增加，极大地降低了找到两个完全相同大数据块的概率。
尽管这些大块内部往往包含大量局部重复片段（如重复的日志、代码或文档段落），但传统以整个块为
单位的粗粒度去重对此类“局部连续冗余”难以检测，导致系统去重效果下降。这揭示了数据缩减系统需要更细粒度的冗余识别。


其二，随着人工智能，特别是大语言生成模型技术的突破性进展，云存储负载中混入越来越多的模型数据。模
型训练产生大量以 \texttt{.pt}、\texttt{.safetensors} 等格式保存的模型文件，其体积动辄达到数百 GB 甚至 TB 级别，
在总存储容量中的占比急剧攀升~\cite{wang2026zipllm}。而面对这些数据，块级去重与统一压缩技术同时失效。

\begin{itemize}
    \item \textbf{去重失效}：模型文件由亿万级相互独立的浮点数张量构成，数据内容呈现高度的随机性和唯一性。
    当系统将不同模型切分为数据块时，几乎每个块都会拥有一个独一无二的指纹，这使得基于全局指纹匹配的去重机制完全失效，去重率趋近于零。
    \item \textbf{压缩失效}：诸如LZ4、Zstandard等通用压缩算法，其核心原理是寻找并消除字节序列层面的重复模式。
    然而，模型数据的冗余并非体现在连续的字节流中，而是源于浮点数的数值分布特征与内部结构。具体而言，在32位单精度浮点数中，
    其二进制表示由符号位、指数位和尾数位构成。在训练好的模型中，绝大部分权重参数的数值集中在某个较小区间内（例如[-2, 2]），
    导致其指数位的前几位高度相似甚至完全相同。此外，由于量化或模型结构带来的规律性，字节层面可能呈现以2字节或4字节为周期的“循环相似”模式。
    这种由高位重复、数值分布集中所构成的“数值冗余”，是传统字节级压缩算法难以捕捉和利用的~\cite{hershcovitch2025zipnn}。
\end{itemize}
% 一方面，模型文件由浮点数张量构成，
% 数据内容呈现高度随机性，使得基于全局指纹匹配的块级去重机制完全失效。另一方面，通用压缩算法旨在寻找字节序列的重复，
% 而模型数据的冗余源于浮点数的数值分布与内部结构——即指数位高位的高度相似性，
% 这种“数值相似性冗余”是传统字节级压缩算法无法捕捉的~\cite{hershcovitch2025zipnn}。


因此，这些混入存储负载中的模型文件，其数值冗余不仅无法通过传统手段缩减存储占用，反而会因其庞大体积而拉低系统的压缩性能，干扰数据缩减流程。
这提示我们或许可以将模型数据分离出传统去重工作流，一方面可以避免模型数据对传统流程性能产生负面影响，另一方面也可以
针对其独特的数值冗余，从更细的浮点数粒度设计专用的数据缩减方法，从而提升整体数据缩减率。

然而，云存储场景下的模型数据分离面临巨大挑战。首先，模型文件通常与其他类型的数据（如训练数据、配置文件、系统日志）共存在同一存储项目中，
而用户在上传文件时并不会提供明确的类型标签。其次，出于隐私和安全考虑，云存储系统难以获得用户数据的语义信息，因此，系统必须依赖对数据内容的实时分析来识别模型数据。
最后，模型数据分布在各类文件之中，除了典型的模型权重文件和训练过程中产生的检查点文件、优化器状态文件等，还可能混杂在归档文件或镜像文件中，增加了识别的复杂性。
如何又快又准地识别并分离模型数据，是一个亟需解决的难题。

综上所述，两种负载变化趋势共同塑造了“模型数据与大块数据共存”的混合负载。当前云存储数据缩减技术面临的困境在于传统技术的冗余识别的粒度与新兴数据特征不匹配，以及混合负载的复杂性。
无论是大尺寸传统数据中存在的“局部连续冗余”，还是混杂的模型数据中隐含的“数值冗余”，都超越了传统块级指纹比对技术的感知范围，
因此，突破这一瓶颈的关键在于，避免混合数据相互干扰的同时，从块级的粗粒度处理，迈向细粒度冗余识别方法。

基于此，本研究提出并构建了一套名为 FHRD (Fine-grained Hybrid Redundancy Data Reduction) 的细粒度冗余识别数据缩减系统。
其核心思想是构建一个统一的、细粒度的数据处理框架。该框架首先在传统去重流水线的基础上，增加了块内连续冗余识别能力，通过对数据块内部的细粒度划分对比，去除局部重复片段。
其次，该框架内置一个轻量级的、模型数据鉴别分离模块，它能实时、准确地判别数据块所蕴含的冗余类型是否符合模型数据规律，从而将模型数据从工作流中分离出来专门处理，避免对细粒度去重流程的负面影响。
最后，框架对分离出的模型数据，采用专用的分组编码方法压缩模型数据的数值冗余。通过这种协同处理架构，FHRD 能够在不显著影响系统吞吐性能的前提下，对数据施加更有效的优化手段，从而系统性地提升混合负载下的整体数据缩减率。

\section{国内外研究现状}

数据去重与压缩技术的研究已历经数十年的发展，从传统的块级去重到细粒度的冗余识别，再到针对特定数据类型的专用压缩，技术路径呈现出不断细化与深入的趋势。

%\textbf{内容定义分块（Content-Defined Chunking）}的
传统块级去重技术是云存储系统中数据缩减的基石，其核心原理是通过消除重复数据块来降低存储开销。
根据分块策略的不同，主要分为固定大小分块与可变长度分块两种技术路线。固定大小分块方案将数据流均分为固定长度的块，实现简单，
性能开销可控，但存在明显的边界效应——数据在分块边界处的微小变化会导致后续所有分块都不匹配，严重降低去重效率~\cite{quinlan2002venti}。
为克服这一局限，可变长度分块技术应运而生，它利用Rabin指纹等滚动哈希算法，根据数据内容本身动态确定分块边界，
使分块结果对数据插入和删除操作更具弹性~\cite{muthitacharoen2001low}。然而，无论是固定还是可变分块，
它们都依赖于寻找完全相同的字节序列，对于AI模型文件中普遍存在的数值相似性冗余，传统方法完全无法识别。
同时，为提升I/O吞吐而采用的MB级大数据块，也使得块内大量存在的局部连续重复无法被检测和消除。

% \subsection{细粒度冗余识别技术}

为突破传统块级去重在大块场景下的局限，学术界提出了多种细粒度冗余识别技术，主要可分为两大
类：面向相似块的增量压缩技术和面向局部连续重复的细粒度去重技术。增量压缩技术旨在通过识别数据块间的相似性，
仅存储差异部分（Delta）来实现压缩。其核心挑战在于如何快速、准确地从海量数据块中找出相似块对。从早期的N-Transform~\cite{broder1997resemblance}到
Finesse~\cite{zhang2019finesse}和Odess~\cite{xia2023design}，研究者们不断优化特征提取与匹配算法
以平衡精度与效率。找到相似块后，Xdelta~\cite{macdonald2000file}和Gdelta~\cite{tan2024design}等差异编码技术则用于
生成紧凑的补丁文件。另一研究方向专注于消除大块数据内部的局部连续重复，Burst~\cite{pengburst}是这方面的典型代表。它通过在MB级大
块内部进行识别并消除首尾长重复序列，有效缓解了因块尺寸增大导致的去重率下降问题。然而，这些细粒度技术在带来更高去重率的同时，
也引入了额外的计算开销和系统复杂性，在混合负载环境中若不加区分地应用，可能导致资源浪费。


在去重之后，通用压缩算法，如Gzip \cite{gailly1992gnu}、LZW \cite{nelson1989lzw}、ANS \cite{duda2015use}，作为数据缩减流水线的第二道工序，负责进一步消除数据块内部的统计冗余。近年来，压缩算法的研究主要围绕速度与压缩率的平衡展开，
产生了如LZ4\footnote{\url{https://github.com/lz4/lz4}} 和Zstandard~\cite{collet2018zstandard}等新一代压缩算法。LZ4以其极致的压缩和解压速度著称，适合实时
高吞吐场景，但压缩率相对较低。Zstandard则致力于在速度与压缩率间取得更优平衡，通过引入有限状态熵编码（FSE）和预训练字典等机制，
提供了灵活的压缩级别选择，在保持高速解压的同时实现了接近甚至超越传统Gzip的压缩率。尽管这些通用压缩算法对文本类数据表现出色，
但它们对模型数据的压缩效果极为有限，其根本原因在于它们基于字节序列重复模式进行压缩，无法捕获模型数据内在的数值冗余。

% \textbf{网络剪枝}（Pruning）旨在通过移除神经网络中的冗余参数来压缩模型。
% \begin{itemize}
%     \item \textbf{非结构化剪枝}：移除单个不重要的权重，通常依据权重大小或对损失函数的影响来判断。虽然灵活，但可能导致不规则的稀疏矩阵，不利于硬件加速。
%     \item \textbf{结构化剪枝}：在更高粒度上（如神经元、通道或层）进行操作，保持了网络的规整结构，便于在通用硬件上高效推理。
% \end{itemize}

% \textbf{模型量化}（Quantization）通过降低权重和激活值的数值精度来压缩模型并加速计算。
% \begin{itemize}
%     \item \textbf{训练后量化}（Post-Training Quantization, PTQ）：无需重新训练，直接对已训练好的 FP32 模型进行量化。实现简单，但可能带来精度损失。
%     \item \textbf{量化感知训练}（Quantization-Aware Training, QAT）：在训练过程中模拟量化效应，使模型能够适应低精度表示，通常能取得更好的性能。
% \end{itemize}


另一方面，面对模型数据的独特性，研究者提出了多种专用压缩技术，其中量化和剪枝是最为重要的两种方向。
模型量化~\cite{gholami2022survey}通过降低权重和激活值的数值精度来减少存储与计算开销，而模型
剪枝~\cite{ma2021effective}则通过移除冗余参数来实现模型压缩。但这两类方法属于有损压缩且严重依赖模型训练过程，通常不适用于要求
数据完整性的云存储服务。此外，还涌现了如ZipNN~\cite{hershcovitch2025zipnn}、FM-Delta~\cite{ning2024fm}和ZipLLM~\cite{wang2026zipllm}等无损压缩方法，它
们利用模型权重间的数值分布规律或跨模型版本的比特级相似性，实现了比通用算法更高的压缩率。但这些方法往往只针对特定格式的模型文件，
无法处理打包文件或识别模型文件中的非模型部分（如文件头、量化内容），限制了其在真实备份场景中的应用。

综上所述，当前数据缩减技术研究面临以下挑战。
\begin{itemize}
    \item 传统块级去重技术在大块数据场景下去重率显著下降，难以利用块内的局部连续冗余。
    \item 通用压缩算法无法捕捉模型数据中的数值冗余，导致压缩效果不佳。
    \item 现有细粒度冗余识别技术多未考虑模型数据的影响，且存在性能方面的不足。
    \item 现有模型专用压缩方法多针对单一数据类型设计，难以适应混合负载环境。
\end{itemize}

\section{本文研究工作与主要贡献}
块级去重技术和通用压缩技术在应对新兴的混合工作负载时效果有限。本研究深入分析发现，
问题的本质在于传统技术体系与新兴数据特征之间的“粒度不匹配”——
传统粗粒度冗余识别方法难以利用大尺寸传统数据内部的局部连续重复模式，也无法有效捕捉模型数据中的数值相似性冗余。
更为严峻的是，针对单一数据类型优化的先进技术（如面向模型数据的专用压缩和面向传统数据的细粒度去重）
在混合负载环境下会产生相互干扰，导致性能下降。

基于此，本研究的核心任务是设计并实现一套面向混合负载的细粒度冗余识别系统，旨在解决三个关键问题：
（1）如何设计并实现细粒度块内冗余的高效去重，以应对数据大块化的挑战；
（2）如何设计并实现模型数据的数值冗余识别与压缩方法，突破传统数据缩减技术的瓶颈，以应对日益增多的模型数据；
（3）如何实现各种优化策略的协同工作，避免混合场景下模型数据对数据缩减流程的负面影响。

为解决上述问题，本文创新性地提出了名为FHRD (Fine-grained Hybrid Redundancy Deduplication) 的细粒度冗余识别数据缩减系统架构。该系统在传统数据缩减流水线的基础上，添加了
细粒度子块去重模块、模型数据鉴别分离模块和模型编码压缩模块，以应对上述问题。本文的工作和贡献主要体现在以下几个方面：

\begin{enumerate}
    \item 揭示了云存储负载呈现出大块化、模型化及混合化的趋势。系统性地分析了传统数据缩减技术在现代云存储环境中失效的根源，明确了两种影响显著的新型冗余：模型数据中的“数值冗余”与大块传统数据中的“局部连续冗余”，并阐述了它们的特征与分布规律。

    \item 通过局部子块的指纹计算与匹配，定位并消除大块数据的局部连续冗余，有效缓解了因块尺寸增大导致的去重率下降问题。

    \item 提出了基于内容特征的高精度块级数据类型鉴别方法，将模型数据的处理从原有流程中剥离。该方法克服了依赖文件元数据进行模型数据识别的局限性，其核心创新在于发现了模型数据在字节层面呈现的“循环相似模式”，并设计了相应的轻量级检测算法。与现有方法相比，该鉴别机制具有精度高、适用性广的优势，且能够准确识别出模型文件中的非模型部分（如文件头、量化内容），避免了误用专用编码器导致的性能退化。

    \item 设计并整合了面向混合场景的差异化冗余处理逻辑。分离了模型数据的处理流程，针对其数值冗余，基于浮点数位结构分析，重组高度相似的指数位部分，将不可压缩数据块转化为可压缩形式；实现了对模型冗余的精准优化与整体去重效能的提升。

    \item 实现并优化了完整的原型系统，进行了系统性的实验验证。本研究基于开源去重系统Destor \cite{fu2015design}实现了FHRD原型。实验结果表明，在混合负载下，FHRD相比传统方法在去重率上取得了20\%至30\%的显著提升。我们通过全面的实验，涵盖了不同模型数据比例、块大小配置及文件形式，详细分析了各模块的性能特征和系统整体开销，为混合负载下的数据缩减提供了有力的评估数据。
\end{enumerate}

\section{论文结构}
本文内容共分为六章，其组织结构如下：

第一章为绪论。阐述研究背景与意义，分析云存储在人工智能时代面临的新挑战，指出传统数据缩减技术在混合负载下的局限性。在此基础上，明确本文的研究目标与主要创新点，并概述论文的组织结构。

第二章为相关工作。系统回顾并对比分析数据去重、通用压缩、细粒度冗余识别及模型专用压缩等方向的代表性工作。通过归纳现有方法的适用场景与不足，为本文方法的设计动机提供理论与实证依据。

第三章为系统设计。针对现有技术的痛点，提出面向混合负载的FHRD系统总体设计。首先分析细粒度冗余特征，明确系统设计目标；继而详细阐述细粒度子块去重、数据类型鉴别分离、模型数据编码等方法的设计；最后梳理系统工作流，为后续实现奠定基础。

第四章为系统实现与优化。聚焦系统落地过程中的核心挑战，给出具体的实现与优化方案。详细介绍字节粒度分组抽样熵值分析、基于熵值结论的字节分组压缩、指数取整的双向子块定长切分等核心方法的实现细节；同时，为提升系统整体性能，设计了数据段聚合、多级索引缓存及流水线并行处理等优化策略。

第五章为实验评估。搭建标准化实验平台，选取多样的非模型、模型及混合负载数据集，设置多种对照方案，从去重率、吞吐量、鉴别准确率等核心指标展开全面评估。通过基准实验、消融实验和参数敏感性实验，系统地验证FHRD在混合负载下的整体优势、各关键模块的贡献及其在不同场景下的适应性。

第六章为总结与展望。系统总结全文研究成果，提炼FHRD系统的核心技术创新与工程实践价值。同时，分析当前研究的局限性，并结合存储技术发展趋势，对未来的研究方向进行展望。

% Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor
% incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis
% nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
% Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu
% fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in
% culpa qui officia deserunt mollit anim id est laborum.

% \section{脚注}
% Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor
% incididunt ut labore et dolore magna aliqua. \footnote{Ut enim ad minim veniam,
% quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
% consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum
% dolore eu fugiat nulla pariatur.}

% \section{字体}

% 上海交通大学是我国历史最悠久的高等学府之一，是教育部直属、教育部与上海市共建的全
% 国重点大学，是国家“七五”、“八五”重点建设和“211 工程”、“985 工程”的首批建
% 设高校。经过 115 年的不懈努力，上海交通大学已经成为一所“综合性、研究型、国际化”
% 的国内一流、国际知名大学，并正在向世界一流大学稳步迈进。 

